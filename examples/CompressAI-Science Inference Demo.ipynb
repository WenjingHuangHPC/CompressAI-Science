{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cf6830",
   "metadata": {},
   "source": [
    "# GPU rans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b96fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hwj/project/CompressAI-Science/compressai/entropy_models/entropy_models.py:417: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1581.)\n",
      "  merged_u8 = torch.frombuffer(memoryview(merged), dtype=torch.uint8).to(device=cdf.device, non_blocking=False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "\n",
    "torch.manual_seed(0)\n",
    "eb = EntropyBottleneck(channels=192).cuda()\n",
    "eb.update(force=True)\n",
    "\n",
    "x = torch.randn(32, 192, 8, 8, device=\"cuda\")\n",
    "\n",
    "# CPU roundtrip\n",
    "eb.use_gpu_ans = False\n",
    "s_cpu = eb.compress(x)\n",
    "xhat_cpu = eb.decompress(s_cpu, (8,8))\n",
    "\n",
    "# GPU roundtrip\n",
    "eb.use_gpu_ans = True\n",
    "s_gpu = eb.compress(x)\n",
    "xhat_gpu = eb.decompress(s_gpu, (8,8))  # 注意 EntropyBottleneck.decompress签名是 (strings,size)\n",
    "\n",
    "# 对比\n",
    "print((xhat_cpu - xhat_gpu).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3607475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass verify: CPU compressed == GPU compressed (bytes match)\n",
      "\n",
      "=== Decompress verify ===\n",
      "max|CPU(cpu)->yhat  - GPU(gpu)->yhat| = 0.0\n",
      "max|CPU(cpu)->yhat  - CPU(gpu)->yhat| = 0.0\n",
      "max|CPU(cpu)->yhat  - GPU(cpu)->yhat| = 0.0\n",
      "Pass verify: CPU/GPU decompress are mutually compatible\n",
      "\n",
      "=== Size ===\n",
      "ga output: torch.Size([512, 192, 8, 8]) 25165824 bytes torch.float32\n",
      "Total compressed bytes: 261808\n",
      "CR: 96.12\n",
      "\n",
      "=== Speed: compress ===\n",
      "CPU compress avg: 602.875 ms / call\n",
      "GPU compress avg: 7.667 ms / call\n",
      "Speedup: 78.63x\n",
      "Throughput CPU: 0.038876 GiB/s\n",
      "Throughput GPU: 3.056780 GiB/s\n",
      "\n",
      "=== Speed: decompress ===\n",
      "CPU decompress avg: 776.710 ms / call\n",
      "GPU decompress avg: 7.397 ms / call\n",
      "Speedup: 105.00x\n",
      "Throughput CPU: 0.030175 GiB/s\n",
      "Throughput GPU: 3.168412 GiB/s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "from compressai.zoo import bmshj2018_factorized\n",
    "\n",
    "def time_cpu(fn, iters=10, warmup=2):\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    t1 = time.perf_counter()\n",
    "    return (t1 - t0) / iters\n",
    "\n",
    "def time_gpu(fn, iters=50, warmup=10):\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    torch.cuda.synchronize()\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    ms = start.elapsed_time(end) / iters\n",
    "    return ms / 1000.0\n",
    "\n",
    "def run():\n",
    "    project_dir = \"/hwj\"\n",
    "    quality = 1\n",
    "    device = \"cuda:0\"\n",
    "\n",
    "    net = bmshj2018_factorized(quality=quality, pretrained=False)\n",
    "    old_state_dict = torch.load(\n",
    "        f\"{project_dir}/data/model/bmshj2018-factorized-prior-{quality}.pth\",\n",
    "        map_location=device,\n",
    "    )\n",
    "    net.load_state_dict(old_state_dict)\n",
    "    net.eval().to(device)\n",
    "\n",
    "    path = \"/hwj/project/aiz-accelerate/data/nyx-dark_matter_density.npy\"\n",
    "\n",
    "    # 1) load npy -> tensor\n",
    "    arr = np.load(path)\n",
    "    x0 = torch.from_numpy(arr).float().to(device)\n",
    "\n",
    "    # 2) analysis transform -> latents\n",
    "    with torch.no_grad():\n",
    "        y = net.g_a(x0)\n",
    "\n",
    "    eb = net.entropy_bottleneck\n",
    "    # eb.update(force=True)  # 通常 pretrained 模型已更新好，如你不确定可以打开\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # A) compress correctness: CPU bytes == GPU bytes\n",
    "    # ------------------------------------------------------------\n",
    "    eb.use_gpu_ans = False\n",
    "    s_cpu = eb.compress(y)\n",
    "\n",
    "    eb.use_gpu_ans = True\n",
    "    s_gpu = eb.compress(y)\n",
    "\n",
    "    assert len(s_cpu) == len(s_gpu)\n",
    "    for i in range(len(s_cpu)):\n",
    "        if s_cpu[i] != s_gpu[i]:\n",
    "            print(\"Mismatch at\", i, len(s_cpu[i]), len(s_gpu[i]))\n",
    "            print(s_cpu[i][:64])\n",
    "            print(s_gpu[i][:64])\n",
    "            raise SystemExit(1)\n",
    "    print(\"Pass verify: CPU compressed == GPU compressed (bytes match)\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # B) decompress correctness (4-way cross check)\n",
    "    # ------------------------------------------------------------\n",
    "    size = y.size()[-2:]  # EntropyBottleneck.decompress(strings, size)\n",
    "\n",
    "    # 1) CPU decode CPU bitstream\n",
    "    eb.use_gpu_ans = False\n",
    "    yhat_cpu_from_cpu = eb.decompress(s_cpu, size)\n",
    "\n",
    "    # 2) GPU decode GPU bitstream\n",
    "    eb.use_gpu_ans = True\n",
    "    yhat_gpu_from_gpu = eb.decompress(s_gpu, size)\n",
    "\n",
    "    # 3) CPU decode GPU bitstream\n",
    "    eb.use_gpu_ans = False\n",
    "    yhat_cpu_from_gpu = eb.decompress(s_gpu, size)\n",
    "\n",
    "    # 4) GPU decode CPU bitstream\n",
    "    eb.use_gpu_ans = True\n",
    "    yhat_gpu_from_cpu = eb.decompress(s_cpu, size)\n",
    "\n",
    "    # 注意：EntropyBottleneck.decompress 会 dequantize 出 float\n",
    "    def max_abs(a, b):\n",
    "        return (a - b).abs().max().item()\n",
    "\n",
    "    m1 = max_abs(yhat_cpu_from_cpu, yhat_gpu_from_gpu)\n",
    "    m2 = max_abs(yhat_cpu_from_cpu, yhat_cpu_from_gpu)\n",
    "    m3 = max_abs(yhat_cpu_from_cpu, yhat_gpu_from_cpu)\n",
    "\n",
    "    print(\"\\n=== Decompress verify ===\")\n",
    "    print(f\"max|CPU(cpu)->yhat  - GPU(gpu)->yhat| = {m1}\")\n",
    "    print(f\"max|CPU(cpu)->yhat  - CPU(gpu)->yhat| = {m2}\")\n",
    "    print(f\"max|CPU(cpu)->yhat  - GPU(cpu)->yhat| = {m3}\")\n",
    "\n",
    "    # 这三个必须为 0（或极小接近 0，如果你 dtype/设备转换引入了差异）\n",
    "    if m1 != 0.0 or m2 != 0.0 or m3 != 0.0:\n",
    "        print(\"Decompress mismatch! (expected exact match)\")\n",
    "        raise SystemExit(2)\n",
    "\n",
    "    print(\"Pass verify: CPU/GPU decompress are mutually compatible\")\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # C) speed tests: compress + decompress\n",
    "    # ------------------------------------------------------------\n",
    "    def cpu_compress():\n",
    "        eb.use_gpu_ans = False\n",
    "        return eb.compress(y)\n",
    "\n",
    "    def gpu_compress():\n",
    "        eb.use_gpu_ans = True\n",
    "        return eb.compress(y)\n",
    "\n",
    "    def cpu_decompress_cpu_stream():\n",
    "        eb.use_gpu_ans = False\n",
    "        return eb.decompress(s_cpu, size)\n",
    "\n",
    "    def gpu_decompress_gpu_stream():\n",
    "        eb.use_gpu_ans = True\n",
    "        return eb.decompress(s_gpu, size)\n",
    "\n",
    "    # compress: CPU path iters 小一些（tolist + loop 很慢）\n",
    "    cpu_comp_sec = time_cpu(cpu_compress, iters=3, warmup=1)\n",
    "    gpu_comp_sec = time_gpu(gpu_compress, iters=30, warmup=5)\n",
    "\n",
    "    # decompress: 同理，CPU path iters 小一点\n",
    "    cpu_decomp_sec = time_cpu(cpu_decompress_cpu_stream, iters=3, warmup=1)\n",
    "    gpu_decomp_sec = time_gpu(gpu_decompress_gpu_stream, iters=30, warmup=5)\n",
    "\n",
    "    total_bytes = sum(len(s) for s in s_cpu)\n",
    "    raw_bytes = y.numel() * 4\n",
    "    gb_raw = raw_bytes / (1024**3)\n",
    "\n",
    "    print(\"\\n=== Size ===\")\n",
    "    print(\"ga output:\", y.shape, f\"{raw_bytes} bytes\", y.dtype)\n",
    "    print(f\"Total compressed bytes: {total_bytes}\")\n",
    "    print(f\"CR: {raw_bytes/total_bytes:.2f}\")\n",
    "\n",
    "    print(\"\\n=== Speed: compress ===\")\n",
    "    print(f\"CPU compress avg: {cpu_comp_sec*1000:.3f} ms / call\")\n",
    "    print(f\"GPU compress avg: {gpu_comp_sec*1000:.3f} ms / call\")\n",
    "    print(f\"Speedup: {cpu_comp_sec/gpu_comp_sec:.2f}x\")\n",
    "    print(f\"Throughput CPU: {gb_raw/cpu_comp_sec:.6f} GiB/s\")\n",
    "    print(f\"Throughput GPU: {gb_raw/gpu_comp_sec:.6f} GiB/s\")\n",
    "\n",
    "    print(\"\\n=== Speed: decompress ===\")\n",
    "    print(f\"CPU decompress avg: {cpu_decomp_sec*1000:.3f} ms / call\")\n",
    "    print(f\"GPU decompress avg: {gpu_decomp_sec*1000:.3f} ms / call\")\n",
    "    print(f\"Speedup: {cpu_decomp_sec/gpu_decomp_sec:.2f}x\")\n",
    "    print(f\"Throughput CPU: {gb_raw/cpu_decomp_sec:.6f} GiB/s\")\n",
    "    print(f\"Throughput GPU: {gb_raw/gpu_decomp_sec:.6f} GiB/s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98063daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compressai-s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
