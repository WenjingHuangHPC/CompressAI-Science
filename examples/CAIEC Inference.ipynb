{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2caa31",
   "metadata": {},
   "source": [
    "# Step 0 — Specify config  and build TensorRT engines\n",
    "\n",
    "Before running CAICE inference, please **choose a component-level precision** and **build TensorRT engines** from your FP32 ONNX.\n",
    "### 1) Specify component precision \n",
    "\n",
    "Use the format:\n",
    "\n",
    "* `ga-fp8`, `ga-fp16`\n",
    "* `gs-fp8`, `gs-fp16`\n",
    "* `ha-fp8`, `ha-fp16`\n",
    "* `hs-fp8`, `hs-fp16`\n",
    "\n",
    "default configs:\n",
    "\n",
    "* `ga-fp8,gs-fp16,ha-fp8(if exist),hs-fp8(if exist)`\n",
    "\n",
    "> Note: For FP8, the build script will quantize the corresponding sub-ONNX (Q/DQ) and then build a **strongly-typed** TensorRT engine.\n",
    "\n",
    "### 2) Define component boundaries (`config.json`)\n",
    "\n",
    "After choosing the precision, you must define **graph boundaries** for each component in `boundaries.config`.\n",
    "The build script uses these boundaries to **extract sub-graphs** (g_a / g_s / h_a / h_s) from the full FP32 ONNX before quantizing and building engines.\n",
    "\n",
    "### What to provide for each component\n",
    "\n",
    "For every component, specify:\n",
    "\n",
    "* `inputs`: a list of **input tensor names** in the ONNX graph\n",
    "* `outputs`: a list of **output tensor names** in the ONNX graph\n",
    "\n",
    "Example (JSON):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"ga\": { \"inputs\": [\"input\"], \"outputs\": [\"/g_a/g_a.6/Conv_output_0\"] },\n",
    "  \"ha\": { \"inputs\": [\"/g_a/g_a.6/Conv_output_0\"], \"outputs\": [\"<ha_out_tensor>\"] },\n",
    "  \"hs\": { \"inputs\": [\"<hs_in_tensor>\"], \"outputs\": [\"/entropy_bottleneck/Transpose_1_output_0\"] },\n",
    "  \"gs\": { \"inputs\": [\"/entropy_bottleneck/Transpose_1_output_0\"], \"outputs\": [\"output\"] }\n",
    "}\n",
    "```\n",
    "\n",
    "### Tips\n",
    "\n",
    "* Tensor names must match **exactly** what appears in the exported ONNX (case-sensitive).\n",
    "* You can inspect tensor names using **Netron** or by printing ONNX graph I/O names in Python.\n",
    "* If you only plan to accelerate a subset of components, you can still define all boundaries now and only build engines for the components listed in your precision config.\n",
    "\n",
    "\n",
    "### 3) Prepare calibration data and input shapes\n",
    "\n",
    "For **FP8 components**, calibration data is required to determine quantization scales.\n",
    "\n",
    "You must also specify the **exact input shape** used to build engines, since TensorRT engines are shape-specific.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141a1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model done.\n",
      "Input data prepared.\n",
      "Running warmup forward...\n",
      "Warmup done.\n",
      "Exporting to ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14602/912217839.py:61: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n",
      "/tmp/ipykernel_14602/912217839.py:77: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export done: /hwj/data/model/onnx/mbt2018-mean-1-f16.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # 定位卡点，确认后可去掉\n",
    "\n",
    "import torch\n",
    "from compressai.zoo import bmshj2018_hyperprior, mbt2018_mean\n",
    "\n",
    "quality = 1\n",
    "project_dir = \"/hwj\"\n",
    "device = \"cuda:0\"\n",
    "model_name = \"mbt2018-mean\"\n",
    "\n",
    "# load model (CPU -> GPU)\n",
    "model = mbt2018_mean(quality=quality, pretrained=False)\n",
    "state = torch.load(f\"{project_dir}/data/model/{model_name}-{quality}.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "model = model.to(device).eval()\n",
    "\n",
    "print(\"Load model done.\")\n",
    "\n",
    "class Wrap(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super().__init__()\n",
    "        self.m = m\n",
    "\n",
    "    # # bmshj2018_hyperprior\n",
    "    # def forward(self, x):\n",
    "    #     y = self.m.g_a(x)\n",
    "    #     z = self.m.h_a(torch.abs(y))\n",
    "    #     z_hat, _ = self.m.entropy_bottleneck(z)\n",
    "    #     scales_hat = self.m.h_s(z_hat)\n",
    "    #     y_hat, _ = self.m.gaussian_conditional(y, scales_hat)\n",
    "    #     x_hat = self.m.g_s(y_hat)\n",
    "    #     return x_hat, scales_hat\n",
    "    # mbt2018_mean\n",
    "    def forward(self, x):\n",
    "        y = self.m.g_a(x)\n",
    "        z = self.m.h_a(y)\n",
    "        z_hat, _ = self.m.entropy_bottleneck(z)\n",
    "        gaussian_params = self.m.h_s(z_hat)\n",
    "        scales_hat, means_hat = gaussian_params.chunk(2, 1)\n",
    "        y_hat, _ = self.m.gaussian_conditional(y, scales_hat, means=means_hat)\n",
    "        x_hat = self.m.g_s(y_hat)\n",
    "        return x_hat, scales_hat\n",
    "\n",
    "wrapped = Wrap(model).eval()\n",
    "\n",
    "dummy_input = torch.randn((512, 3, 128, 128), device=device, dtype=torch.float32)\n",
    "print(\"Input data prepared.\")\n",
    "\n",
    "# 先确认 forward 是否真的能跑完\n",
    "with torch.no_grad():\n",
    "    print(\"Running warmup forward...\")\n",
    "    _ = wrapped(dummy_input)\n",
    "    torch.cuda.synchronize()\n",
    "print(\"Warmup done.\")\n",
    "\n",
    "onnx_path = f\"{project_dir}/data/model/onnx/{model_name}-{quality}-f32.onnx\"\n",
    "print(\"Exporting to ONNX...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        wrapped,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"x_hat\", \"scales_hat\"],\n",
    "        opset_version=17,\n",
    "        # do_constant_folding=False,\n",
    "    )\n",
    "    \n",
    "model = model.eval().to(device).to(torch.float16)\n",
    "dummy_input = torch.randn((512, 3, 128, 128), device=device, dtype=torch.float16)\n",
    "onnx_path = f\"{project_dir}/data/model/onnx/{model_name}-{quality}-f16.onnx\"\n",
    "wrapped = Wrap(model).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        wrapped,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"x_hat\", \"scales_hat\"],\n",
    "        opset_version=17,\n",
    "        # do_constant_folding=False,\n",
    "    )\n",
    "\n",
    "print(\"Export done:\", onnx_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3478b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Extracted ga (fp16): /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ga_fp16.onnx\n",
      "[OK] Extracted ha (fp16): /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ha_fp16.onnx\n",
      "[OK] Extracted hs (fp16): /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/hs_fp16.onnx\n",
      "[OK] Extracted gs (fp16): /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/gs_fp16.onnx\n",
      "[Shape] ha fixed input shape = (512, 192, 8, 8) (reuse calib file)\n",
      "[Shape] hs fixed input shape = (512, 128, 2, 2) (reuse calib file)\n",
      "[Shape] gs fixed input shape = (512, 192, 8, 8) (reuse calib file)\n",
      "[FixShape] ga_fp16.onnx input=input -> (512, 3, 128, 128)\n",
      "[FixShape] ha_fp16.onnx input=/g_a/g_a.6/Conv_output_0 -> (512, 192, 8, 8)\n",
      "[FixShape] hs_fp16.onnx input=/entropy_bottleneck/Transpose_1_output_0 -> (512, 128, 2, 2)\n",
      "[FixShape] gs_fp16.onnx input=/gaussian_conditional/Add_output_0 -> (512, 192, 8, 8)\n",
      "\n",
      "[Engine] Building ga engine (fp16): /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ga/fp16.engine\n",
      "trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ga_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ga/fp16.engine --fp16\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ga_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ga/fp16.engine --fp16\n",
      "[01/14/2026-07:45:01] [I] === Model Options ===\n",
      "[01/14/2026-07:45:01] [I] Format: ONNX\n",
      "[01/14/2026-07:45:01] [I] Model: /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ga_fp16.onnx\n",
      "[01/14/2026-07:45:01] [I] Output:\n",
      "[01/14/2026-07:45:01] [I] === Build Options ===\n",
      "[01/14/2026-07:45:01] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
      "[01/14/2026-07:45:01] [I] avgTiming: 8\n",
      "[01/14/2026-07:45:01] [I] Precision: FP32+FP16\n",
      "[01/14/2026-07:45:01] [I] LayerPrecisions: \n",
      "[01/14/2026-07:45:01] [I] Layer Device Types: \n",
      "[01/14/2026-07:45:01] [I] Calibration: \n",
      "[01/14/2026-07:45:01] [I] Refit: Disabled\n",
      "[01/14/2026-07:45:01] [I] Strip weights: Disabled\n",
      "[01/14/2026-07:45:01] [I] Version Compatible: Disabled\n",
      "[01/14/2026-07:45:01] [I] ONNX Plugin InstanceNorm: Disabled\n",
      "[01/14/2026-07:45:01] [I] ONNX kENABLE_UINT8_AND_ASYMMETRIC_QUANTIZATION_DLA flag: Disabled\n",
      "[01/14/2026-07:45:01] [I] TensorRT runtime: full\n",
      "[01/14/2026-07:45:01] [I] Lean DLL Path: \n",
      "[01/14/2026-07:45:01] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
      "[01/14/2026-07:45:01] [I] Exclude Lean Runtime: Disabled\n",
      "[01/14/2026-07:45:01] [I] Sparsity: Disabled\n",
      "[01/14/2026-07:45:01] [I] Safe mode: Disabled\n",
      "[01/14/2026-07:45:01] [I] Build DLA standalone loadable: Disabled\n",
      "[01/14/2026-07:45:01] [I] Allow GPU fallback for DLA: Disabled\n",
      "[01/14/2026-07:45:01] [I] DirectIO mode: Disabled\n",
      "[01/14/2026-07:45:01] [I] Restricted mode: Disabled\n",
      "[01/14/2026-07:45:01] [I] Skip inference: Disabled\n",
      "[01/14/2026-07:45:01] [I] Save engine: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ga/fp16.engine\n",
      "[01/14/2026-07:45:01] [I] Load engine: \n",
      "[01/14/2026-07:45:01] [I] Profiling verbosity: 0\n",
      "[01/14/2026-07:45:01] [I] Tactic sources: Using default tactic sources\n",
      "[01/14/2026-07:45:01] [I] timingCacheMode: local\n",
      "[01/14/2026-07:45:01] [I] timingCacheFile: \n",
      "[01/14/2026-07:45:01] [I] Enable Compilation Cache: Enabled\n",
      "[01/14/2026-07:45:01] [I] Enable Monitor Memory: Disabled\n",
      "[01/14/2026-07:45:01] [I] errorOnTimingCacheMiss: Disabled\n",
      "[01/14/2026-07:45:01] [I] Preview Features: Use default preview flags.\n",
      "[01/14/2026-07:45:01] [I] MaxAuxStreams: -1\n",
      "[01/14/2026-07:45:01] [I] BuilderOptimizationLevel: -1\n",
      "[01/14/2026-07:45:01] [I] MaxTactics: -1\n",
      "[01/14/2026-07:45:01] [I] Calibration Profile Index: 0\n",
      "[01/14/2026-07:45:01] [I] Weight Streaming: Disabled\n",
      "[01/14/2026-07:45:01] [I] Runtime Platform: Same As Build\n",
      "[01/14/2026-07:45:01] [I] Debug Tensors: \n",
      "[01/14/2026-07:45:01] [I] Distributive Independence: Disabled\n",
      "[01/14/2026-07:45:01] [I] Mark Unfused Tensors As Debug Tensors: Disabled\n",
      "[01/14/2026-07:45:01] [I] Input(s)s format: fp32:CHW\n",
      "[01/14/2026-07:45:01] [I] Output(s)s format: fp32:CHW\n",
      "[01/14/2026-07:45:01] [I] Input build shapes: model\n",
      "[01/14/2026-07:45:01] [I] Input calibration shapes: model\n",
      "[01/14/2026-07:45:01] [I] === System Options ===\n",
      "[01/14/2026-07:45:01] [I] Device: 0\n",
      "[01/14/2026-07:45:01] [I] DLACore: \n",
      "[01/14/2026-07:45:01] [I] Plugins:\n",
      "[01/14/2026-07:45:01] [I] setPluginsToSerialize:\n",
      "[01/14/2026-07:45:01] [I] dynamicPlugins:\n",
      "[01/14/2026-07:45:01] [I] ignoreParsedPluginLibs: 0\n",
      "[01/14/2026-07:45:01] [I] \n",
      "[01/14/2026-07:45:01] [I] === Inference Options ===\n",
      "[01/14/2026-07:45:01] [I] Batch: Explicit\n",
      "[01/14/2026-07:45:01] [I] Input inference shapes: model\n",
      "[01/14/2026-07:45:01] [I] Iterations: 10\n",
      "[01/14/2026-07:45:01] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/14/2026-07:45:01] [I] Sleep time: 0ms\n",
      "[01/14/2026-07:45:01] [I] Idle time: 0ms\n",
      "[01/14/2026-07:45:01] [I] Inference Streams: 1\n",
      "[01/14/2026-07:45:01] [I] ExposeDMA: Disabled\n",
      "[01/14/2026-07:45:01] [I] Data transfers: Enabled\n",
      "[01/14/2026-07:45:01] [I] Spin-wait: Disabled\n",
      "[01/14/2026-07:45:01] [I] Multithreading: Disabled\n",
      "[01/14/2026-07:45:01] [I] CUDA Graph: Disabled\n",
      "[01/14/2026-07:45:01] [I] Separate profiling: Disabled\n",
      "[01/14/2026-07:45:01] [I] Time Deserialize: Disabled\n",
      "[01/14/2026-07:45:01] [I] Time Refit: Disabled\n",
      "[01/14/2026-07:45:01] [I] NVTX verbosity: 0\n",
      "[01/14/2026-07:45:01] [I] Persistent Cache Ratio: 0\n",
      "[01/14/2026-07:45:01] [I] Optimization Profile Index: 0\n",
      "[01/14/2026-07:45:01] [I] Weight Streaming Budget: 100.000000%\n",
      "[01/14/2026-07:45:01] [I] Inputs:\n",
      "[01/14/2026-07:45:01] [I] Debug Tensor Save Destinations:\n",
      "[01/14/2026-07:45:01] [I] Dump All Debug Tensor in Formats: \n",
      "[01/14/2026-07:45:01] [I] === Reporting Options ===\n",
      "[01/14/2026-07:45:01] [I] Verbose: Disabled\n",
      "[01/14/2026-07:45:01] [I] Averages: 10 inferences\n",
      "[01/14/2026-07:45:01] [I] Percentiles: 90,95,99\n",
      "[01/14/2026-07:45:01] [I] Dump refittable layers:Disabled\n",
      "[01/14/2026-07:45:01] [I] Dump output: Disabled\n",
      "[01/14/2026-07:45:01] [I] Profile: Disabled\n",
      "[01/14/2026-07:45:01] [I] Export timing to JSON file: \n",
      "[01/14/2026-07:45:01] [I] Export output to JSON file: \n",
      "[01/14/2026-07:45:01] [I] Export profile to JSON file: \n",
      "[01/14/2026-07:45:01] [I] \n",
      "[01/14/2026-07:45:01] [I] === Device Information ===\n",
      "[01/14/2026-07:45:01] [I] Available Devices: \n",
      "[01/14/2026-07:45:01] [I]   Device 0: \"NVIDIA H100 PCIe\" UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:45:01] [I]   Device 1: \"NVIDIA H100 PCIe\" UUID: GPU-ad162803-098e-b980-5e1b-5623d5adc58b\n",
      "[01/14/2026-07:45:01] [I] Selected Device: NVIDIA H100 PCIe\n",
      "[01/14/2026-07:45:01] [I] Selected Device ID: 0\n",
      "[01/14/2026-07:45:01] [I] Selected Device UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:45:01] [I] Compute Capability: 9.0\n",
      "[01/14/2026-07:45:01] [I] SMs: 114\n",
      "[01/14/2026-07:45:01] [I] Device Global Memory: 81079 MiB\n",
      "[01/14/2026-07:45:01] [I] Shared Memory per SM: 228 KiB\n",
      "[01/14/2026-07:45:01] [I] Memory Bus Width: 5120 bits (ECC enabled)\n",
      "[01/14/2026-07:45:01] [I] Application Compute Clock Rate: 1.755 GHz\n",
      "[01/14/2026-07:45:01] [I] Application Memory Clock Rate: 1.593 GHz\n",
      "[01/14/2026-07:45:01] [I] \n",
      "[01/14/2026-07:45:01] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
      "[01/14/2026-07:45:01] [I] \n",
      "[01/14/2026-07:45:01] [I] TensorRT version: 10.12.0\n",
      "[01/14/2026-07:45:01] [I] Loading standard plugins\n",
      "[01/14/2026-07:45:01] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 44, GPU 6989 (MiB)\n",
      "[01/14/2026-07:45:04] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1927, GPU +8, now: CPU 2173, GPU 6999 (MiB)\n",
      "[01/14/2026-07:45:04] [I] Start parsing network model.\n",
      "[01/14/2026-07:45:04] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:45:04] [I] [TRT] Input filename:   /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ga_fp16.onnx\n",
      "[01/14/2026-07:45:04] [I] [TRT] ONNX IR version:  0.0.8\n",
      "[01/14/2026-07:45:04] [I] [TRT] Opset version:    17\n",
      "[01/14/2026-07:45:04] [I] [TRT] Producer name:    onnx.utils.extract_model\n",
      "[01/14/2026-07:45:04] [I] [TRT] Producer version: \n",
      "[01/14/2026-07:45:04] [I] [TRT] Domain:           \n",
      "[01/14/2026-07:45:04] [I] [TRT] Model version:    0\n",
      "[01/14/2026-07:45:04] [I] [TRT] Doc string:       \n",
      "[01/14/2026-07:45:04] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:45:04] [I] Finished parsing network model. Parse time: 0.00582231\n",
      "[01/14/2026-07:45:04] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/14/2026-07:46:25] [I] [TRT] Compiler backend is used during engine build.\n",
      "[01/14/2026-07:46:38] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[01/14/2026-07:46:39] [I] [TRT] Total Host Persistent Memory: 54912 bytes\n",
      "[01/14/2026-07:46:39] [I] [TRT] Total Device Persistent Memory: 0 bytes\n",
      "[01/14/2026-07:46:39] [I] [TRT] Max Scratch Memory: 33280 bytes\n",
      "[01/14/2026-07:46:39] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 47 steps to complete.\n",
      "[01/14/2026-07:46:39] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 1.88822ms to assign 18 blocks to 47 nodes requiring 1610749952 bytes.\n",
      "[01/14/2026-07:46:39] [I] [TRT] Total Activation Memory: 1610747392 bytes\n",
      "[01/14/2026-07:46:39] [I] [TRT] Total Weights Memory: 2997504 bytes\n",
      "[01/14/2026-07:46:39] [I] [TRT] Compiler backend is used during engine execution.\n",
      "[01/14/2026-07:46:39] [I] [TRT] Engine generation completed in 95.301 seconds.\n",
      "[01/14/2026-07:46:39] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 3072 MiB\n",
      "[01/14/2026-07:46:39] [I] Engine built in 95.3534 sec.\n",
      "[01/14/2026-07:46:39] [I] Created engine with size: 3.46473 MiB\n",
      "[01/14/2026-07:46:39] [I] [TRT] Loaded engine size: 3 MiB\n",
      "[01/14/2026-07:46:39] [I] Engine deserialized in 0.0147545 sec.\n",
      "[01/14/2026-07:46:39] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1536, now: CPU 0, GPU 1538 (MiB)\n",
      "[01/14/2026-07:46:39] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/14/2026-07:46:39] [I] Created execution context with device memory size: 1536.13 MiB\n",
      "[01/14/2026-07:46:39] [I] Using random values for input input\n",
      "[01/14/2026-07:46:40] [I] Input binding for input with dimensions 512x3x128x128 is created.\n",
      "[01/14/2026-07:46:40] [I] Output binding for /g_a/g_a.6/Conv_output_0 with dimensions 512x192x8x8 is created.\n",
      "[01/14/2026-07:46:40] [I] Starting inference\n",
      "[01/14/2026-07:46:43] [I] Warmup completed 33 queries over 200 ms\n",
      "[01/14/2026-07:46:43] [I] Timing trace has 491 queries over 3.01214 s\n",
      "[01/14/2026-07:46:43] [I] \n",
      "[01/14/2026-07:46:43] [I] === Trace details ===\n",
      "[01/14/2026-07:46:43] [I] Trace averages of 10 runs:\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14297 ms - Host latency: 6.3306 ms (enqueue 6.06984 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14209 ms - Host latency: 6.32463 ms (enqueue 6.06538 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14333 ms - Host latency: 6.32672 ms (enqueue 6.06965 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14189 ms - Host latency: 6.32269 ms (enqueue 6.0637 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.13765 ms - Host latency: 6.3214 ms (enqueue 6.06101 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14604 ms - Host latency: 6.32948 ms (enqueue 6.06985 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14783 ms - Host latency: 6.32981 ms (enqueue 6.07018 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14666 ms - Host latency: 6.32955 ms (enqueue 6.07094 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.1486 ms - Host latency: 6.32894 ms (enqueue 6.07234 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.14649 ms - Host latency: 6.32956 ms (enqueue 6.07131 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.18671 ms - Host latency: 6.37037 ms (enqueue 6.11161 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.24469 ms - Host latency: 6.43082 ms (enqueue 6.16888 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.23708 ms - Host latency: 6.42331 ms (enqueue 6.16097 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.32494 ms - Host latency: 6.50838 ms (enqueue 6.24578 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.17037 ms - Host latency: 6.35339 ms (enqueue 6.09202 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.17355 ms - Host latency: 6.35472 ms (enqueue 6.09427 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16481 ms - Host latency: 6.34543 ms (enqueue 6.08755 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16034 ms - Host latency: 6.34283 ms (enqueue 6.0771 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.1485 ms - Host latency: 6.33069 ms (enqueue 6.0683 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.15303 ms - Host latency: 6.3384 ms (enqueue 6.07689 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.1651 ms - Host latency: 6.34548 ms (enqueue 6.08485 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.15397 ms - Host latency: 6.33663 ms (enqueue 6.07511 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16239 ms - Host latency: 6.34376 ms (enqueue 6.08447 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16461 ms - Host latency: 6.34362 ms (enqueue 6.0839 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16907 ms - Host latency: 6.35543 ms (enqueue 6.09215 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16051 ms - Host latency: 6.34252 ms (enqueue 6.08036 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16724 ms - Host latency: 6.34972 ms (enqueue 6.08925 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.18148 ms - Host latency: 6.36428 ms (enqueue 6.10453 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.20463 ms - Host latency: 6.38792 ms (enqueue 6.12448 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.19755 ms - Host latency: 6.38015 ms (enqueue 6.1184 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.17983 ms - Host latency: 6.3631 ms (enqueue 6.10206 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.18127 ms - Host latency: 6.36716 ms (enqueue 6.10447 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.18474 ms - Host latency: 6.36545 ms (enqueue 6.10542 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.174 ms - Host latency: 6.35544 ms (enqueue 6.09456 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.18022 ms - Host latency: 6.36479 ms (enqueue 6.10415 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16716 ms - Host latency: 6.35098 ms (enqueue 6.09016 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.174 ms - Host latency: 6.35774 ms (enqueue 6.09661 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16746 ms - Host latency: 6.35044 ms (enqueue 6.09053 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16333 ms - Host latency: 6.34663 ms (enqueue 6.08638 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.15925 ms - Host latency: 6.33772 ms (enqueue 6.07927 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16489 ms - Host latency: 6.34856 ms (enqueue 6.08738 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.1615 ms - Host latency: 6.34143 ms (enqueue 6.08437 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16489 ms - Host latency: 6.34963 ms (enqueue 6.08699 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.17356 ms - Host latency: 6.35879 ms (enqueue 6.09707 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.20327 ms - Host latency: 6.3842 ms (enqueue 6.1262 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.20623 ms - Host latency: 6.38748 ms (enqueue 6.12715 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.17603 ms - Host latency: 6.35774 ms (enqueue 6.09846 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.16975 ms - Host latency: 6.34966 ms (enqueue 6.0907 ms)\n",
      "[01/14/2026-07:46:43] [I] Average on 10 runs - GPU latency: 5.19238 ms - Host latency: 6.37461 ms (enqueue 6.11443 ms)\n",
      "[01/14/2026-07:46:43] [I] \n",
      "[01/14/2026-07:46:43] [I] === Performance summary ===\n",
      "[01/14/2026-07:46:43] [I] Throughput: 163.007 qps\n",
      "[01/14/2026-07:46:43] [I] Latency: min = 6.31024 ms, max = 7.61957 ms, mean = 6.35577 ms, median = 6.34692 ms, percentile(90%) = 6.38538 ms, percentile(95%) = 6.39795 ms, percentile(99%) = 6.45013 ms\n",
      "[01/14/2026-07:46:43] [I] Enqueue Time: min = 6.04175 ms, max = 7.35535 ms, mean = 6.09538 ms, median = 6.08667 ms, percentile(90%) = 6.12427 ms, percentile(95%) = 6.138 ms, percentile(99%) = 6.18884 ms\n",
      "[01/14/2026-07:46:43] [I] H2D Latency: min = 0.9198 ms, max = 0.944214 ms, mean = 0.923355 ms, median = 0.921387 ms, percentile(90%) = 0.933594 ms, percentile(95%) = 0.935547 ms, percentile(99%) = 0.940002 ms\n",
      "[01/14/2026-07:46:43] [I] GPU Compute Time: min = 5.12889 ms, max = 6.43884 ms, mean = 5.17304 ms, median = 5.16382 ms, percentile(90%) = 5.20337 ms, percentile(95%) = 5.2168 ms, percentile(99%) = 5.26965 ms\n",
      "[01/14/2026-07:46:43] [I] D2H Latency: min = 0.233887 ms, max = 0.28595 ms, mean = 0.259376 ms, median = 0.258301 ms, percentile(90%) = 0.26416 ms, percentile(95%) = 0.266968 ms, percentile(99%) = 0.277222 ms\n",
      "[01/14/2026-07:46:43] [I] Total Host Walltime: 3.01214 s\n",
      "[01/14/2026-07:46:43] [I] Total GPU Compute Time: 2.53996 s\n",
      "[01/14/2026-07:46:43] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[01/14/2026-07:46:43] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[01/14/2026-07:46:43] [W] * GPU compute time is unstable, with coefficient of variance = 1.24115%.\n",
      "[01/14/2026-07:46:43] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
      "[01/14/2026-07:46:43] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/14/2026-07:46:43] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ga_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ga/fp16.engine --fp16\n",
      "[OK] FP16 Engine built: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ga/fp16.engine\n",
      "\n",
      "[Engine] Building ha engine (fp16): /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ha/fp16.engine\n",
      "trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ha_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ha/fp16.engine --fp16\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ha_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ha/fp16.engine --fp16\n",
      "[01/14/2026-07:46:43] [I] === Model Options ===\n",
      "[01/14/2026-07:46:43] [I] Format: ONNX\n",
      "[01/14/2026-07:46:43] [I] Model: /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ha_fp16.onnx\n",
      "[01/14/2026-07:46:43] [I] Output:\n",
      "[01/14/2026-07:46:43] [I] === Build Options ===\n",
      "[01/14/2026-07:46:43] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
      "[01/14/2026-07:46:43] [I] avgTiming: 8\n",
      "[01/14/2026-07:46:43] [I] Precision: FP32+FP16\n",
      "[01/14/2026-07:46:43] [I] LayerPrecisions: \n",
      "[01/14/2026-07:46:43] [I] Layer Device Types: \n",
      "[01/14/2026-07:46:43] [I] Calibration: \n",
      "[01/14/2026-07:46:43] [I] Refit: Disabled\n",
      "[01/14/2026-07:46:43] [I] Strip weights: Disabled\n",
      "[01/14/2026-07:46:43] [I] Version Compatible: Disabled\n",
      "[01/14/2026-07:46:43] [I] ONNX Plugin InstanceNorm: Disabled\n",
      "[01/14/2026-07:46:43] [I] ONNX kENABLE_UINT8_AND_ASYMMETRIC_QUANTIZATION_DLA flag: Disabled\n",
      "[01/14/2026-07:46:43] [I] TensorRT runtime: full\n",
      "[01/14/2026-07:46:43] [I] Lean DLL Path: \n",
      "[01/14/2026-07:46:43] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
      "[01/14/2026-07:46:43] [I] Exclude Lean Runtime: Disabled\n",
      "[01/14/2026-07:46:43] [I] Sparsity: Disabled\n",
      "[01/14/2026-07:46:43] [I] Safe mode: Disabled\n",
      "[01/14/2026-07:46:43] [I] Build DLA standalone loadable: Disabled\n",
      "[01/14/2026-07:46:43] [I] Allow GPU fallback for DLA: Disabled\n",
      "[01/14/2026-07:46:43] [I] DirectIO mode: Disabled\n",
      "[01/14/2026-07:46:43] [I] Restricted mode: Disabled\n",
      "[01/14/2026-07:46:43] [I] Skip inference: Disabled\n",
      "[01/14/2026-07:46:43] [I] Save engine: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ha/fp16.engine\n",
      "[01/14/2026-07:46:43] [I] Load engine: \n",
      "[01/14/2026-07:46:43] [I] Profiling verbosity: 0\n",
      "[01/14/2026-07:46:43] [I] Tactic sources: Using default tactic sources\n",
      "[01/14/2026-07:46:43] [I] timingCacheMode: local\n",
      "[01/14/2026-07:46:43] [I] timingCacheFile: \n",
      "[01/14/2026-07:46:43] [I] Enable Compilation Cache: Enabled\n",
      "[01/14/2026-07:46:43] [I] Enable Monitor Memory: Disabled\n",
      "[01/14/2026-07:46:43] [I] errorOnTimingCacheMiss: Disabled\n",
      "[01/14/2026-07:46:43] [I] Preview Features: Use default preview flags.\n",
      "[01/14/2026-07:46:43] [I] MaxAuxStreams: -1\n",
      "[01/14/2026-07:46:43] [I] BuilderOptimizationLevel: -1\n",
      "[01/14/2026-07:46:43] [I] MaxTactics: -1\n",
      "[01/14/2026-07:46:43] [I] Calibration Profile Index: 0\n",
      "[01/14/2026-07:46:43] [I] Weight Streaming: Disabled\n",
      "[01/14/2026-07:46:43] [I] Runtime Platform: Same As Build\n",
      "[01/14/2026-07:46:43] [I] Debug Tensors: \n",
      "[01/14/2026-07:46:43] [I] Distributive Independence: Disabled\n",
      "[01/14/2026-07:46:43] [I] Mark Unfused Tensors As Debug Tensors: Disabled\n",
      "[01/14/2026-07:46:43] [I] Input(s)s format: fp32:CHW\n",
      "[01/14/2026-07:46:43] [I] Output(s)s format: fp32:CHW\n",
      "[01/14/2026-07:46:43] [I] Input build shapes: model\n",
      "[01/14/2026-07:46:43] [I] Input calibration shapes: model\n",
      "[01/14/2026-07:46:43] [I] === System Options ===\n",
      "[01/14/2026-07:46:43] [I] Device: 0\n",
      "[01/14/2026-07:46:43] [I] DLACore: \n",
      "[01/14/2026-07:46:43] [I] Plugins:\n",
      "[01/14/2026-07:46:43] [I] setPluginsToSerialize:\n",
      "[01/14/2026-07:46:43] [I] dynamicPlugins:\n",
      "[01/14/2026-07:46:43] [I] ignoreParsedPluginLibs: 0\n",
      "[01/14/2026-07:46:43] [I] \n",
      "[01/14/2026-07:46:43] [I] === Inference Options ===\n",
      "[01/14/2026-07:46:43] [I] Batch: Explicit\n",
      "[01/14/2026-07:46:43] [I] Input inference shapes: model\n",
      "[01/14/2026-07:46:43] [I] Iterations: 10\n",
      "[01/14/2026-07:46:43] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/14/2026-07:46:43] [I] Sleep time: 0ms\n",
      "[01/14/2026-07:46:43] [I] Idle time: 0ms\n",
      "[01/14/2026-07:46:43] [I] Inference Streams: 1\n",
      "[01/14/2026-07:46:43] [I] ExposeDMA: Disabled\n",
      "[01/14/2026-07:46:43] [I] Data transfers: Enabled\n",
      "[01/14/2026-07:46:43] [I] Spin-wait: Disabled\n",
      "[01/14/2026-07:46:43] [I] Multithreading: Disabled\n",
      "[01/14/2026-07:46:43] [I] CUDA Graph: Disabled\n",
      "[01/14/2026-07:46:43] [I] Separate profiling: Disabled\n",
      "[01/14/2026-07:46:43] [I] Time Deserialize: Disabled\n",
      "[01/14/2026-07:46:43] [I] Time Refit: Disabled\n",
      "[01/14/2026-07:46:43] [I] NVTX verbosity: 0\n",
      "[01/14/2026-07:46:43] [I] Persistent Cache Ratio: 0\n",
      "[01/14/2026-07:46:43] [I] Optimization Profile Index: 0\n",
      "[01/14/2026-07:46:43] [I] Weight Streaming Budget: 100.000000%\n",
      "[01/14/2026-07:46:43] [I] Inputs:\n",
      "[01/14/2026-07:46:43] [I] Debug Tensor Save Destinations:\n",
      "[01/14/2026-07:46:43] [I] Dump All Debug Tensor in Formats: \n",
      "[01/14/2026-07:46:43] [I] === Reporting Options ===\n",
      "[01/14/2026-07:46:43] [I] Verbose: Disabled\n",
      "[01/14/2026-07:46:43] [I] Averages: 10 inferences\n",
      "[01/14/2026-07:46:43] [I] Percentiles: 90,95,99\n",
      "[01/14/2026-07:46:43] [I] Dump refittable layers:Disabled\n",
      "[01/14/2026-07:46:43] [I] Dump output: Disabled\n",
      "[01/14/2026-07:46:43] [I] Profile: Disabled\n",
      "[01/14/2026-07:46:43] [I] Export timing to JSON file: \n",
      "[01/14/2026-07:46:43] [I] Export output to JSON file: \n",
      "[01/14/2026-07:46:43] [I] Export profile to JSON file: \n",
      "[01/14/2026-07:46:43] [I] \n",
      "[01/14/2026-07:46:43] [I] === Device Information ===\n",
      "[01/14/2026-07:46:43] [I] Available Devices: \n",
      "[01/14/2026-07:46:43] [I]   Device 0: \"NVIDIA H100 PCIe\" UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:46:43] [I]   Device 1: \"NVIDIA H100 PCIe\" UUID: GPU-ad162803-098e-b980-5e1b-5623d5adc58b\n",
      "[01/14/2026-07:46:43] [I] Selected Device: NVIDIA H100 PCIe\n",
      "[01/14/2026-07:46:43] [I] Selected Device ID: 0\n",
      "[01/14/2026-07:46:43] [I] Selected Device UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:46:43] [I] Compute Capability: 9.0\n",
      "[01/14/2026-07:46:43] [I] SMs: 114\n",
      "[01/14/2026-07:46:43] [I] Device Global Memory: 81079 MiB\n",
      "[01/14/2026-07:46:43] [I] Shared Memory per SM: 228 KiB\n",
      "[01/14/2026-07:46:43] [I] Memory Bus Width: 5120 bits (ECC enabled)\n",
      "[01/14/2026-07:46:43] [I] Application Compute Clock Rate: 1.755 GHz\n",
      "[01/14/2026-07:46:43] [I] Application Memory Clock Rate: 1.593 GHz\n",
      "[01/14/2026-07:46:43] [I] \n",
      "[01/14/2026-07:46:43] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
      "[01/14/2026-07:46:43] [I] \n",
      "[01/14/2026-07:46:43] [I] TensorRT version: 10.12.0\n",
      "[01/14/2026-07:46:43] [I] Loading standard plugins\n",
      "[01/14/2026-07:46:43] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 44, GPU 6989 (MiB)\n",
      "[01/14/2026-07:46:46] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1927, GPU +8, now: CPU 2173, GPU 6999 (MiB)\n",
      "[01/14/2026-07:46:46] [I] Start parsing network model.\n",
      "[01/14/2026-07:46:46] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:46:46] [I] [TRT] Input filename:   /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ha_fp16.onnx\n",
      "[01/14/2026-07:46:46] [I] [TRT] ONNX IR version:  0.0.8\n",
      "[01/14/2026-07:46:46] [I] [TRT] Opset version:    17\n",
      "[01/14/2026-07:46:46] [I] [TRT] Producer name:    onnx.utils.extract_model\n",
      "[01/14/2026-07:46:46] [I] [TRT] Producer version: \n",
      "[01/14/2026-07:46:46] [I] [TRT] Domain:           \n",
      "[01/14/2026-07:46:46] [I] [TRT] Model version:    0\n",
      "[01/14/2026-07:46:46] [I] [TRT] Doc string:       \n",
      "[01/14/2026-07:46:46] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:46:46] [I] Finished parsing network model. Parse time: 0.00333673\n",
      "[01/14/2026-07:46:46] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/14/2026-07:46:52] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[01/14/2026-07:46:53] [I] [TRT] Total Host Persistent Memory: 20352 bytes\n",
      "[01/14/2026-07:46:53] [I] [TRT] Total Device Persistent Memory: 0 bytes\n",
      "[01/14/2026-07:46:53] [I] [TRT] Max Scratch Memory: 512 bytes\n",
      "[01/14/2026-07:46:53] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 6 steps to complete.\n",
      "[01/14/2026-07:46:53] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.021019ms to assign 3 blocks to 6 nodes requiring 20972032 bytes.\n",
      "[01/14/2026-07:46:53] [I] [TRT] Total Activation Memory: 20972032 bytes\n",
      "[01/14/2026-07:46:53] [I] [TRT] Total Weights Memory: 2082816 bytes\n",
      "[01/14/2026-07:46:53] [I] [TRT] Engine generation completed in 7.36856 seconds.\n",
      "[01/14/2026-07:46:53] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 42 MiB\n",
      "[01/14/2026-07:46:53] [I] Engine built in 7.40434 sec.\n",
      "[01/14/2026-07:46:53] [I] Created engine with size: 2.18767 MiB\n",
      "[01/14/2026-07:46:53] [I] [TRT] Loaded engine size: 2 MiB\n",
      "[01/14/2026-07:46:53] [I] Engine deserialized in 0.00997713 sec.\n",
      "[01/14/2026-07:46:53] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +20, now: CPU 0, GPU 21 (MiB)\n",
      "[01/14/2026-07:46:53] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/14/2026-07:46:53] [I] Created execution context with device memory size: 20.0005 MiB\n",
      "[01/14/2026-07:46:53] [I] Using random values for input /g_a/g_a.6/Conv_output_0\n",
      "[01/14/2026-07:46:53] [I] Input binding for /g_a/g_a.6/Conv_output_0 with dimensions 512x192x8x8 is created.\n",
      "[01/14/2026-07:46:53] [I] Output binding for /h_a/h_a.4/Conv_output_0 with dimensions 512x128x2x2 is created.\n",
      "[01/14/2026-07:46:53] [I] Starting inference\n",
      "[01/14/2026-07:46:57] [I] Warmup completed 463 queries over 200 ms\n",
      "[01/14/2026-07:46:57] [I] Timing trace has 6957 queries over 3.00344 s\n",
      "[01/14/2026-07:46:57] [I] \n",
      "[01/14/2026-07:46:57] [I] === Trace details ===\n",
      "[01/14/2026-07:46:57] [I] Trace averages of 10 runs:\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164603 ms - Host latency: 0.411021 ms (enqueue 0.394313 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16526 ms - Host latency: 0.41127 ms (enqueue 0.394998 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164832 ms - Host latency: 0.411218 ms (enqueue 0.394916 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.410852 ms (enqueue 0.39597 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164694 ms - Host latency: 0.411292 ms (enqueue 0.396188 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164812 ms - Host latency: 0.412079 ms (enqueue 0.395639 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16494 ms - Host latency: 0.411102 ms (enqueue 0.395824 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164607 ms - Host latency: 0.411113 ms (enqueue 0.395821 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16514 ms - Host latency: 0.411307 ms (enqueue 0.39487 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165031 ms - Host latency: 0.411169 ms (enqueue 0.395955 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165649 ms - Host latency: 0.411874 ms (enqueue 0.396359 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16479 ms - Host latency: 0.411443 ms (enqueue 0.395 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165309 ms - Host latency: 0.411527 ms (enqueue 0.395801 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165411 ms - Host latency: 0.412903 ms (enqueue 0.396492 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165021 ms - Host latency: 0.41163 ms (enqueue 0.396646 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164929 ms - Host latency: 0.411115 ms (enqueue 0.396179 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164459 ms - Host latency: 0.410617 ms (enqueue 0.394232 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164951 ms - Host latency: 0.410977 ms (enqueue 0.396124 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164597 ms - Host latency: 0.41076 ms (enqueue 0.394385 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164774 ms - Host latency: 0.410886 ms (enqueue 0.394995 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164752 ms - Host latency: 0.411707 ms (enqueue 0.394556 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16496 ms - Host latency: 0.412427 ms (enqueue 0.39505 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165912 ms - Host latency: 0.412082 ms (enqueue 0.394864 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16488 ms - Host latency: 0.411252 ms (enqueue 0.394177 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164951 ms - Host latency: 0.411087 ms (enqueue 0.39429 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165805 ms - Host latency: 0.411908 ms (enqueue 0.396408 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164725 ms - Host latency: 0.411337 ms (enqueue 0.39584 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164651 ms - Host latency: 0.410925 ms (enqueue 0.395374 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165808 ms - Host latency: 0.412115 ms (enqueue 0.395779 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.166599 ms - Host latency: 0.413968 ms (enqueue 0.398846 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.167276 ms - Host latency: 0.413327 ms (enqueue 0.396725 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16687 ms - Host latency: 0.412918 ms (enqueue 0.397317 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.166702 ms - Host latency: 0.412894 ms (enqueue 0.396976 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.166367 ms - Host latency: 0.412631 ms (enqueue 0.396356 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.166617 ms - Host latency: 0.413513 ms (enqueue 0.397479 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.167163 ms - Host latency: 0.413086 ms (enqueue 0.39649 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16723 ms - Host latency: 0.414359 ms (enqueue 0.398163 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.166486 ms - Host latency: 0.41254 ms (enqueue 0.397314 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.166406 ms - Host latency: 0.41254 ms (enqueue 0.395981 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165698 ms - Host latency: 0.411951 ms (enqueue 0.396881 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164828 ms - Host latency: 0.410965 ms (enqueue 0.395255 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165219 ms - Host latency: 0.411319 ms (enqueue 0.395157 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164374 ms - Host latency: 0.411078 ms (enqueue 0.395224 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164252 ms - Host latency: 0.411655 ms (enqueue 0.395938 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164456 ms - Host latency: 0.410754 ms (enqueue 0.395566 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164456 ms - Host latency: 0.410529 ms (enqueue 0.393744 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164703 ms - Host latency: 0.410913 ms (enqueue 0.395477 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164172 ms - Host latency: 0.410526 ms (enqueue 0.394101 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164365 ms - Host latency: 0.410413 ms (enqueue 0.395236 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16488 ms - Host latency: 0.412878 ms (enqueue 0.396713 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165247 ms - Host latency: 0.411462 ms (enqueue 0.395618 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165515 ms - Host latency: 0.41293 ms (enqueue 0.396295 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165775 ms - Host latency: 0.411868 ms (enqueue 0.396848 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165768 ms - Host latency: 0.411887 ms (enqueue 0.395657 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164801 ms - Host latency: 0.41127 ms (enqueue 0.395081 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164883 ms - Host latency: 0.411038 ms (enqueue 0.39566 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165027 ms - Host latency: 0.411972 ms (enqueue 0.39671 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164633 ms - Host latency: 0.410867 ms (enqueue 0.394531 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164597 ms - Host latency: 0.411572 ms (enqueue 0.395993 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164569 ms - Host latency: 0.411719 ms (enqueue 0.39588 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165466 ms - Host latency: 0.411816 ms (enqueue 0.396094 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165662 ms - Host latency: 0.411987 ms (enqueue 0.395862 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164557 ms - Host latency: 0.4108 ms (enqueue 0.395255 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164752 ms - Host latency: 0.411047 ms (enqueue 0.395221 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164566 ms - Host latency: 0.411972 ms (enqueue 0.39534 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164914 ms - Host latency: 0.412024 ms (enqueue 0.396689 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411115 ms (enqueue 0.395972 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164587 ms - Host latency: 0.411139 ms (enqueue 0.394763 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164618 ms - Host latency: 0.411047 ms (enqueue 0.395789 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16441 ms - Host latency: 0.411108 ms (enqueue 0.395032 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164636 ms - Host latency: 0.411047 ms (enqueue 0.395056 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164456 ms - Host latency: 0.411597 ms (enqueue 0.395807 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164536 ms - Host latency: 0.411475 ms (enqueue 0.396204 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164398 ms - Host latency: 0.410754 ms (enqueue 0.394055 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164514 ms - Host latency: 0.411798 ms (enqueue 0.39613 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165045 ms - Host latency: 0.411853 ms (enqueue 0.396094 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165723 ms - Host latency: 0.412164 ms (enqueue 0.39505 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165216 ms - Host latency: 0.41156 ms (enqueue 0.394922 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165515 ms - Host latency: 0.41203 ms (enqueue 0.395502 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165454 ms - Host latency: 0.412109 ms (enqueue 0.39541 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164508 ms - Host latency: 0.411853 ms (enqueue 0.397015 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164771 ms - Host latency: 0.412012 ms (enqueue 0.396832 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164197 ms - Host latency: 0.410516 ms (enqueue 0.393518 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163721 ms - Host latency: 0.410217 ms (enqueue 0.392993 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164197 ms - Host latency: 0.410419 ms (enqueue 0.394537 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164594 ms - Host latency: 0.410864 ms (enqueue 0.394971 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164398 ms - Host latency: 0.412262 ms (enqueue 0.39696 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164984 ms - Host latency: 0.412256 ms (enqueue 0.397046 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164758 ms - Host latency: 0.411475 ms (enqueue 0.396008 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164594 ms - Host latency: 0.41131 ms (enqueue 0.395062 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164471 ms - Host latency: 0.41087 ms (enqueue 0.39494 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164233 ms - Host latency: 0.410419 ms (enqueue 0.393518 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164221 ms - Host latency: 0.411176 ms (enqueue 0.39455 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165228 ms - Host latency: 0.412585 ms (enqueue 0.396729 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163928 ms - Host latency: 0.41026 ms (enqueue 0.394751 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164191 ms - Host latency: 0.411444 ms (enqueue 0.396271 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164111 ms - Host latency: 0.411469 ms (enqueue 0.39494 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164227 ms - Host latency: 0.410529 ms (enqueue 0.39436 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164081 ms - Host latency: 0.410278 ms (enqueue 0.39353 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164447 ms - Host latency: 0.410571 ms (enqueue 0.394421 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164691 ms - Host latency: 0.411353 ms (enqueue 0.395941 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164307 ms - Host latency: 0.411096 ms (enqueue 0.394659 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164502 ms - Host latency: 0.412299 ms (enqueue 0.396082 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164606 ms - Host latency: 0.410992 ms (enqueue 0.395496 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164258 ms - Host latency: 0.410468 ms (enqueue 0.395374 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164636 ms - Host latency: 0.411047 ms (enqueue 0.395642 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164783 ms - Host latency: 0.410999 ms (enqueue 0.395819 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164239 ms - Host latency: 0.410522 ms (enqueue 0.393799 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164667 ms - Host latency: 0.412201 ms (enqueue 0.396942 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165851 ms - Host latency: 0.412274 ms (enqueue 0.395935 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164764 ms - Host latency: 0.41134 ms (enqueue 0.394812 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164691 ms - Host latency: 0.41203 ms (enqueue 0.395734 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.411243 ms (enqueue 0.395636 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16496 ms - Host latency: 0.411108 ms (enqueue 0.393781 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164917 ms - Host latency: 0.411267 ms (enqueue 0.394861 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165369 ms - Host latency: 0.411749 ms (enqueue 0.396075 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164679 ms - Host latency: 0.412 ms (enqueue 0.395276 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164972 ms - Host latency: 0.412524 ms (enqueue 0.397144 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165118 ms - Host latency: 0.411407 ms (enqueue 0.396173 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411169 ms (enqueue 0.395587 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165448 ms - Host latency: 0.411603 ms (enqueue 0.395782 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165009 ms - Host latency: 0.4112 ms (enqueue 0.395728 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164624 ms - Host latency: 0.410822 ms (enqueue 0.395068 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164453 ms - Host latency: 0.411841 ms (enqueue 0.396991 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164459 ms - Host latency: 0.412201 ms (enqueue 0.395422 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165167 ms - Host latency: 0.411719 ms (enqueue 0.393896 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165692 ms - Host latency: 0.412543 ms (enqueue 0.395331 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16521 ms - Host latency: 0.411646 ms (enqueue 0.395062 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16485 ms - Host latency: 0.41106 ms (enqueue 0.393542 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16499 ms - Host latency: 0.41142 ms (enqueue 0.395685 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165399 ms - Host latency: 0.412408 ms (enqueue 0.396783 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164539 ms - Host latency: 0.410693 ms (enqueue 0.39563 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164874 ms - Host latency: 0.412219 ms (enqueue 0.395679 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164697 ms - Host latency: 0.412115 ms (enqueue 0.39447 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165625 ms - Host latency: 0.411798 ms (enqueue 0.395752 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164941 ms - Host latency: 0.411157 ms (enqueue 0.395984 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164508 ms - Host latency: 0.410657 ms (enqueue 0.394965 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165137 ms - Host latency: 0.411475 ms (enqueue 0.395392 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164874 ms - Host latency: 0.411322 ms (enqueue 0.394012 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165045 ms - Host latency: 0.412421 ms (enqueue 0.397253 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164923 ms - Host latency: 0.411926 ms (enqueue 0.395245 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164563 ms - Host latency: 0.410785 ms (enqueue 0.394727 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165601 ms - Host latency: 0.411981 ms (enqueue 0.396558 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165588 ms - Host latency: 0.411884 ms (enqueue 0.395361 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165063 ms - Host latency: 0.411279 ms (enqueue 0.396472 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164655 ms - Host latency: 0.41217 ms (enqueue 0.397632 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164386 ms - Host latency: 0.410919 ms (enqueue 0.394409 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165112 ms - Host latency: 0.411566 ms (enqueue 0.396942 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164679 ms - Host latency: 0.412 ms (enqueue 0.39696 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164648 ms - Host latency: 0.411041 ms (enqueue 0.395581 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165448 ms - Host latency: 0.411652 ms (enqueue 0.396191 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165094 ms - Host latency: 0.411163 ms (enqueue 0.39502 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165027 ms - Host latency: 0.411298 ms (enqueue 0.396002 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164905 ms - Host latency: 0.411176 ms (enqueue 0.395728 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165375 ms - Host latency: 0.411859 ms (enqueue 0.39527 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.413422 ms (enqueue 0.396368 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165198 ms - Host latency: 0.41145 ms (enqueue 0.39516 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164777 ms - Host latency: 0.411121 ms (enqueue 0.395538 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164917 ms - Host latency: 0.411078 ms (enqueue 0.394867 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165063 ms - Host latency: 0.4112 ms (enqueue 0.3953 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164386 ms - Host latency: 0.410669 ms (enqueue 0.394489 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164899 ms - Host latency: 0.412378 ms (enqueue 0.395868 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164716 ms - Host latency: 0.412305 ms (enqueue 0.396313 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165173 ms - Host latency: 0.411981 ms (enqueue 0.3966 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16524 ms - Host latency: 0.41153 ms (enqueue 0.394452 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165881 ms - Host latency: 0.412036 ms (enqueue 0.396295 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411139 ms (enqueue 0.395331 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165021 ms - Host latency: 0.411383 ms (enqueue 0.395673 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165094 ms - Host latency: 0.413843 ms (enqueue 0.397992 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164978 ms - Host latency: 0.411267 ms (enqueue 0.395514 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164923 ms - Host latency: 0.412085 ms (enqueue 0.396765 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16452 ms - Host latency: 0.410571 ms (enqueue 0.395056 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165131 ms - Host latency: 0.411334 ms (enqueue 0.396759 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164807 ms - Host latency: 0.411005 ms (enqueue 0.394971 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164429 ms - Host latency: 0.410608 ms (enqueue 0.39613 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163959 ms - Host latency: 0.411279 ms (enqueue 0.395959 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164465 ms - Host latency: 0.410687 ms (enqueue 0.39502 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164117 ms - Host latency: 0.411493 ms (enqueue 0.394952 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164545 ms - Host latency: 0.412134 ms (enqueue 0.396222 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16441 ms - Host latency: 0.411206 ms (enqueue 0.394958 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164453 ms - Host latency: 0.41073 ms (enqueue 0.394708 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164709 ms - Host latency: 0.411072 ms (enqueue 0.39505 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164258 ms - Host latency: 0.410712 ms (enqueue 0.393921 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163794 ms - Host latency: 0.411157 ms (enqueue 0.394696 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164008 ms - Host latency: 0.410559 ms (enqueue 0.394727 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164001 ms - Host latency: 0.410266 ms (enqueue 0.395154 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.447217 ms - Host latency: 0.693549 ms (enqueue 0.677179 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164423 ms - Host latency: 0.410736 ms (enqueue 0.394202 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164172 ms - Host latency: 0.41048 ms (enqueue 0.394366 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164142 ms - Host latency: 0.410431 ms (enqueue 0.394653 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164258 ms - Host latency: 0.411591 ms (enqueue 0.396448 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16521 ms - Host latency: 0.413574 ms (enqueue 0.397485 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164709 ms - Host latency: 0.411133 ms (enqueue 0.395032 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164453 ms - Host latency: 0.41073 ms (enqueue 0.393762 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411121 ms (enqueue 0.395081 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164307 ms - Host latency: 0.41073 ms (enqueue 0.394263 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164197 ms - Host latency: 0.410645 ms (enqueue 0.394519 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164124 ms - Host latency: 0.411523 ms (enqueue 0.395959 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164136 ms - Host latency: 0.410376 ms (enqueue 0.393445 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163867 ms - Host latency: 0.411365 ms (enqueue 0.396313 ms)\n",
      "[01/14/2026-07:46:57] [I] ... Omitting 2957 lines\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16521 ms - Host latency: 0.413403 ms (enqueue 0.396655 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164795 ms - Host latency: 0.410962 ms (enqueue 0.395435 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165259 ms - Host latency: 0.411548 ms (enqueue 0.395776 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164697 ms - Host latency: 0.410815 ms (enqueue 0.396509 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164941 ms - Host latency: 0.411206 ms (enqueue 0.394873 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164966 ms - Host latency: 0.411328 ms (enqueue 0.394995 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164404 ms - Host latency: 0.412012 ms (enqueue 0.395898 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165063 ms - Host latency: 0.412622 ms (enqueue 0.397192 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164819 ms - Host latency: 0.41123 ms (enqueue 0.395532 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164941 ms - Host latency: 0.411182 ms (enqueue 0.394605 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411108 ms (enqueue 0.395117 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164771 ms - Host latency: 0.41123 ms (enqueue 0.39729 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.410864 ms (enqueue 0.396265 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164697 ms - Host latency: 0.414771 ms (enqueue 0.39834 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165454 ms - Host latency: 0.41228 ms (enqueue 0.395386 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16543 ms - Host latency: 0.411816 ms (enqueue 0.395947 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165381 ms - Host latency: 0.411621 ms (enqueue 0.395898 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164795 ms - Host latency: 0.410913 ms (enqueue 0.394556 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165137 ms - Host latency: 0.411694 ms (enqueue 0.394971 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164966 ms - Host latency: 0.411255 ms (enqueue 0.395117 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164355 ms - Host latency: 0.412109 ms (enqueue 0.394995 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164722 ms - Host latency: 0.41123 ms (enqueue 0.394873 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164917 ms - Host latency: 0.411865 ms (enqueue 0.396191 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164331 ms - Host latency: 0.411768 ms (enqueue 0.396338 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164331 ms - Host latency: 0.410596 ms (enqueue 0.395215 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164624 ms - Host latency: 0.41106 ms (enqueue 0.395215 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16499 ms - Host latency: 0.41123 ms (enqueue 0.395996 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165186 ms - Host latency: 0.411401 ms (enqueue 0.395703 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16499 ms - Host latency: 0.412402 ms (enqueue 0.396997 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16521 ms - Host latency: 0.412769 ms (enqueue 0.395459 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165454 ms - Host latency: 0.412085 ms (enqueue 0.39519 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165234 ms - Host latency: 0.411572 ms (enqueue 0.396533 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165479 ms - Host latency: 0.411938 ms (enqueue 0.394263 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411182 ms (enqueue 0.395703 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164502 ms - Host latency: 0.410791 ms (enqueue 0.394556 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165186 ms - Host latency: 0.412915 ms (enqueue 0.397119 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.412134 ms (enqueue 0.396387 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164526 ms - Host latency: 0.411499 ms (enqueue 0.395386 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164648 ms - Host latency: 0.411255 ms (enqueue 0.396216 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165405 ms - Host latency: 0.411963 ms (enqueue 0.39541 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165381 ms - Host latency: 0.41167 ms (enqueue 0.394775 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165137 ms - Host latency: 0.411597 ms (enqueue 0.395801 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16521 ms - Host latency: 0.412891 ms (enqueue 0.397095 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.410962 ms (enqueue 0.395044 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164648 ms - Host latency: 0.411792 ms (enqueue 0.397168 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164429 ms - Host latency: 0.412549 ms (enqueue 0.394556 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164966 ms - Host latency: 0.411328 ms (enqueue 0.394238 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411206 ms (enqueue 0.395654 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165601 ms - Host latency: 0.41189 ms (enqueue 0.395825 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164551 ms - Host latency: 0.410962 ms (enqueue 0.394019 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164819 ms - Host latency: 0.411084 ms (enqueue 0.39458 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165039 ms - Host latency: 0.412842 ms (enqueue 0.396484 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164746 ms - Host latency: 0.412207 ms (enqueue 0.395776 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165405 ms - Host latency: 0.412378 ms (enqueue 0.396484 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.411328 ms (enqueue 0.396118 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411084 ms (enqueue 0.394922 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411255 ms (enqueue 0.395117 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164819 ms - Host latency: 0.412427 ms (enqueue 0.395093 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411816 ms (enqueue 0.395166 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164282 ms - Host latency: 0.410474 ms (enqueue 0.395288 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164722 ms - Host latency: 0.412354 ms (enqueue 0.396631 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164819 ms - Host latency: 0.41189 ms (enqueue 0.394824 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.410767 ms (enqueue 0.395605 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.1646 ms - Host latency: 0.410889 ms (enqueue 0.395581 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165234 ms - Host latency: 0.411499 ms (enqueue 0.395654 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164453 ms - Host latency: 0.41062 ms (enqueue 0.394775 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164746 ms - Host latency: 0.412451 ms (enqueue 0.39707 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16499 ms - Host latency: 0.412524 ms (enqueue 0.395825 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165161 ms - Host latency: 0.41145 ms (enqueue 0.395557 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165259 ms - Host latency: 0.411597 ms (enqueue 0.395239 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165479 ms - Host latency: 0.411719 ms (enqueue 0.395923 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165283 ms - Host latency: 0.411719 ms (enqueue 0.396021 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164771 ms - Host latency: 0.41167 ms (enqueue 0.39541 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164526 ms - Host latency: 0.412036 ms (enqueue 0.396069 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164624 ms - Host latency: 0.41123 ms (enqueue 0.39585 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164404 ms - Host latency: 0.410718 ms (enqueue 0.394849 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164673 ms - Host latency: 0.411011 ms (enqueue 0.394775 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.41123 ms (enqueue 0.394751 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165649 ms - Host latency: 0.412061 ms (enqueue 0.396265 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16521 ms - Host latency: 0.412598 ms (enqueue 0.396582 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164941 ms - Host latency: 0.411353 ms (enqueue 0.39502 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411914 ms (enqueue 0.394775 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164819 ms - Host latency: 0.412231 ms (enqueue 0.396826 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164746 ms - Host latency: 0.41106 ms (enqueue 0.396094 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164111 ms - Host latency: 0.410571 ms (enqueue 0.39353 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164673 ms - Host latency: 0.410962 ms (enqueue 0.395728 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.1646 ms - Host latency: 0.411377 ms (enqueue 0.394189 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165332 ms - Host latency: 0.411743 ms (enqueue 0.394214 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165063 ms - Host latency: 0.412793 ms (enqueue 0.396118 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164697 ms - Host latency: 0.412183 ms (enqueue 0.397339 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16499 ms - Host latency: 0.411401 ms (enqueue 0.395337 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164795 ms - Host latency: 0.411084 ms (enqueue 0.395264 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164746 ms - Host latency: 0.411133 ms (enqueue 0.395508 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165137 ms - Host latency: 0.411499 ms (enqueue 0.395532 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165186 ms - Host latency: 0.412769 ms (enqueue 0.39563 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165674 ms - Host latency: 0.413159 ms (enqueue 0.397461 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.411182 ms (enqueue 0.395288 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164429 ms - Host latency: 0.411719 ms (enqueue 0.396362 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.1646 ms - Host latency: 0.411426 ms (enqueue 0.39585 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164307 ms - Host latency: 0.411182 ms (enqueue 0.396021 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164673 ms - Host latency: 0.411475 ms (enqueue 0.394238 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163794 ms - Host latency: 0.41023 ms (enqueue 0.394214 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163892 ms - Host latency: 0.411157 ms (enqueue 0.395483 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16438 ms - Host latency: 0.410742 ms (enqueue 0.394116 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164282 ms - Host latency: 0.412036 ms (enqueue 0.396875 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164331 ms - Host latency: 0.412061 ms (enqueue 0.396973 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164355 ms - Host latency: 0.410864 ms (enqueue 0.393896 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164795 ms - Host latency: 0.411084 ms (enqueue 0.394678 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164478 ms - Host latency: 0.410718 ms (enqueue 0.395532 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164429 ms - Host latency: 0.41145 ms (enqueue 0.396118 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163965 ms - Host latency: 0.411597 ms (enqueue 0.394849 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.41123 ms (enqueue 0.396753 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163647 ms - Host latency: 0.410132 ms (enqueue 0.393799 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163794 ms - Host latency: 0.410034 ms (enqueue 0.394458 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163867 ms - Host latency: 0.410254 ms (enqueue 0.393213 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164038 ms - Host latency: 0.410132 ms (enqueue 0.395166 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164355 ms - Host latency: 0.410498 ms (enqueue 0.394727 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164258 ms - Host latency: 0.411621 ms (enqueue 0.395483 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164453 ms - Host latency: 0.410718 ms (enqueue 0.395068 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165161 ms - Host latency: 0.414111 ms (enqueue 0.3979 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164795 ms - Host latency: 0.411182 ms (enqueue 0.394263 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164966 ms - Host latency: 0.411133 ms (enqueue 0.395996 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.411133 ms (enqueue 0.395557 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411133 ms (enqueue 0.39668 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164478 ms - Host latency: 0.410669 ms (enqueue 0.394141 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16416 ms - Host latency: 0.411768 ms (enqueue 0.39646 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165015 ms - Host latency: 0.412866 ms (enqueue 0.396729 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165747 ms - Host latency: 0.412231 ms (enqueue 0.396045 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16604 ms - Host latency: 0.412354 ms (enqueue 0.396436 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411182 ms (enqueue 0.395068 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165356 ms - Host latency: 0.411646 ms (enqueue 0.396265 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165015 ms - Host latency: 0.411353 ms (enqueue 0.395166 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164722 ms - Host latency: 0.413452 ms (enqueue 0.397607 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165356 ms - Host latency: 0.411597 ms (enqueue 0.395508 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165332 ms - Host latency: 0.413037 ms (enqueue 0.39751 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165332 ms - Host latency: 0.41167 ms (enqueue 0.39624 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164478 ms - Host latency: 0.410767 ms (enqueue 0.394971 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165063 ms - Host latency: 0.411206 ms (enqueue 0.396851 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.1646 ms - Host latency: 0.410937 ms (enqueue 0.395459 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164526 ms - Host latency: 0.412036 ms (enqueue 0.395581 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164307 ms - Host latency: 0.410693 ms (enqueue 0.39541 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165063 ms - Host latency: 0.41189 ms (enqueue 0.39668 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165234 ms - Host latency: 0.412817 ms (enqueue 0.397144 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164355 ms - Host latency: 0.410815 ms (enqueue 0.395801 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164648 ms - Host latency: 0.410986 ms (enqueue 0.394653 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16416 ms - Host latency: 0.410522 ms (enqueue 0.39397 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411035 ms (enqueue 0.394873 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164331 ms - Host latency: 0.411914 ms (enqueue 0.395117 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163916 ms - Host latency: 0.411597 ms (enqueue 0.395044 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164038 ms - Host latency: 0.410278 ms (enqueue 0.392505 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16416 ms - Host latency: 0.410449 ms (enqueue 0.393213 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163452 ms - Host latency: 0.410327 ms (enqueue 0.393506 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164795 ms - Host latency: 0.411133 ms (enqueue 0.394629 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164062 ms - Host latency: 0.41023 ms (enqueue 0.394434 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164209 ms - Host latency: 0.411938 ms (enqueue 0.395996 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.1646 ms - Host latency: 0.411255 ms (enqueue 0.394946 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164966 ms - Host latency: 0.412085 ms (enqueue 0.396509 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164307 ms - Host latency: 0.411841 ms (enqueue 0.395068 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164941 ms - Host latency: 0.41123 ms (enqueue 0.39563 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164136 ms - Host latency: 0.411011 ms (enqueue 0.394458 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165332 ms - Host latency: 0.411914 ms (enqueue 0.395361 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163623 ms - Host latency: 0.410205 ms (enqueue 0.394336 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163403 ms - Host latency: 0.411108 ms (enqueue 0.395605 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.412329 ms (enqueue 0.395361 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16438 ms - Host latency: 0.410596 ms (enqueue 0.394556 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.163745 ms - Host latency: 0.410107 ms (enqueue 0.393164 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164478 ms - Host latency: 0.410645 ms (enqueue 0.395557 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165161 ms - Host latency: 0.411377 ms (enqueue 0.396362 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164941 ms - Host latency: 0.411914 ms (enqueue 0.394971 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16582 ms - Host latency: 0.413306 ms (enqueue 0.397412 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411841 ms (enqueue 0.395874 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165552 ms - Host latency: 0.411841 ms (enqueue 0.395825 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165137 ms - Host latency: 0.412451 ms (enqueue 0.395752 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411377 ms (enqueue 0.395459 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164331 ms - Host latency: 0.410669 ms (enqueue 0.394751 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164624 ms - Host latency: 0.41084 ms (enqueue 0.396216 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.411475 ms (enqueue 0.394653 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164551 ms - Host latency: 0.411206 ms (enqueue 0.395825 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.412402 ms (enqueue 0.396045 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164917 ms - Host latency: 0.411938 ms (enqueue 0.396582 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164844 ms - Host latency: 0.411133 ms (enqueue 0.396265 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165283 ms - Host latency: 0.411719 ms (enqueue 0.396094 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165259 ms - Host latency: 0.411548 ms (enqueue 0.395093 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.16499 ms - Host latency: 0.411328 ms (enqueue 0.395825 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165381 ms - Host latency: 0.412378 ms (enqueue 0.395703 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165503 ms - Host latency: 0.413843 ms (enqueue 0.398291 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411182 ms (enqueue 0.395752 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164795 ms - Host latency: 0.41106 ms (enqueue 0.396338 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164673 ms - Host latency: 0.410937 ms (enqueue 0.394873 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164868 ms - Host latency: 0.411133 ms (enqueue 0.394482 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164648 ms - Host latency: 0.410864 ms (enqueue 0.396265 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164502 ms - Host latency: 0.412134 ms (enqueue 0.395898 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165137 ms - Host latency: 0.411865 ms (enqueue 0.396191 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165625 ms - Host latency: 0.411963 ms (enqueue 0.395557 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164893 ms - Host latency: 0.412451 ms (enqueue 0.397314 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165015 ms - Host latency: 0.41145 ms (enqueue 0.396094 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165112 ms - Host latency: 0.41145 ms (enqueue 0.394849 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164771 ms - Host latency: 0.411255 ms (enqueue 0.395752 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.164722 ms - Host latency: 0.411011 ms (enqueue 0.396338 ms)\n",
      "[01/14/2026-07:46:57] [I] Average on 10 runs - GPU latency: 0.165601 ms - Host latency: 0.845728 ms (enqueue 0.393457 ms)\n",
      "[01/14/2026-07:46:57] [I] \n",
      "[01/14/2026-07:46:57] [I] === Performance summary ===\n",
      "[01/14/2026-07:46:57] [I] Throughput: 2316.34 qps\n",
      "[01/14/2026-07:46:57] [I] Latency: min = 0.407959 ms, max = 4.75391 ms, mean = 0.413115 ms, median = 0.411011 ms, percentile(90%) = 0.412903 ms, percentile(95%) = 0.415283 ms, percentile(99%) = 0.422852 ms\n",
      "[01/14/2026-07:46:57] [I] Enqueue Time: min = 0.384399 ms, max = 4.57812 ms, mean = 0.396501 ms, median = 0.395508 ms, percentile(90%) = 0.39856 ms, percentile(95%) = 0.400208 ms, percentile(99%) = 0.407227 ms\n",
      "[01/14/2026-07:46:57] [I] H2D Latency: min = 0.230713 ms, max = 4.56421 ms, mean = 0.232479 ms, median = 0.231445 ms, percentile(90%) = 0.231934 ms, percentile(95%) = 0.232178 ms, percentile(99%) = 0.243652 ms\n",
      "[01/14/2026-07:46:57] [I] GPU Compute Time: min = 0.161743 ms, max = 4.35254 ms, mean = 0.165796 ms, median = 0.164612 ms, percentile(90%) = 0.165955 ms, percentile(95%) = 0.166748 ms, percentile(99%) = 0.169617 ms\n",
      "[01/14/2026-07:46:57] [I] D2H Latency: min = 0.0138855 ms, max = 0.0229492 ms, mean = 0.0148422 ms, median = 0.0147705 ms, percentile(90%) = 0.0151367 ms, percentile(95%) = 0.0151978 ms, percentile(99%) = 0.0153809 ms\n",
      "[01/14/2026-07:46:57] [I] Total Host Walltime: 3.00344 s\n",
      "[01/14/2026-07:46:57] [I] Total GPU Compute Time: 1.15344 s\n",
      "[01/14/2026-07:46:57] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[01/14/2026-07:46:57] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[01/14/2026-07:46:57] [W] * Throughput may be bound by host-to-device transfers for the inputs rather than GPU Compute and the GPU may be under-utilized.\n",
      "[01/14/2026-07:46:57] [W]   Add --noDataTransfers flag to disable data transfers.\n",
      "[01/14/2026-07:46:57] [W] * GPU compute time is unstable, with coefficient of variance = 36.55%.\n",
      "[01/14/2026-07:46:57] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
      "[01/14/2026-07:46:57] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/14/2026-07:46:57] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/ha_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ha/fp16.engine --fp16\n",
      "[OK] FP16 Engine built: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ha/fp16.engine\n",
      "\n",
      "[Engine] Building hs engine (fp16): /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/hs/fp16.engine\n",
      "trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/hs_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/hs/fp16.engine --fp16\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/hs_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/hs/fp16.engine --fp16\n",
      "[01/14/2026-07:46:57] [I] === Model Options ===\n",
      "[01/14/2026-07:46:57] [I] Format: ONNX\n",
      "[01/14/2026-07:46:57] [I] Model: /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/hs_fp16.onnx\n",
      "[01/14/2026-07:46:57] [I] Output:\n",
      "[01/14/2026-07:46:57] [I] === Build Options ===\n",
      "[01/14/2026-07:46:57] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
      "[01/14/2026-07:46:57] [I] avgTiming: 8\n",
      "[01/14/2026-07:46:57] [I] Precision: FP32+FP16\n",
      "[01/14/2026-07:46:57] [I] LayerPrecisions: \n",
      "[01/14/2026-07:46:57] [I] Layer Device Types: \n",
      "[01/14/2026-07:46:57] [I] Calibration: \n",
      "[01/14/2026-07:46:57] [I] Refit: Disabled\n",
      "[01/14/2026-07:46:57] [I] Strip weights: Disabled\n",
      "[01/14/2026-07:46:57] [I] Version Compatible: Disabled\n",
      "[01/14/2026-07:46:57] [I] ONNX Plugin InstanceNorm: Disabled\n",
      "[01/14/2026-07:46:57] [I] ONNX kENABLE_UINT8_AND_ASYMMETRIC_QUANTIZATION_DLA flag: Disabled\n",
      "[01/14/2026-07:46:57] [I] TensorRT runtime: full\n",
      "[01/14/2026-07:46:57] [I] Lean DLL Path: \n",
      "[01/14/2026-07:46:57] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
      "[01/14/2026-07:46:57] [I] Exclude Lean Runtime: Disabled\n",
      "[01/14/2026-07:46:57] [I] Sparsity: Disabled\n",
      "[01/14/2026-07:46:57] [I] Safe mode: Disabled\n",
      "[01/14/2026-07:46:57] [I] Build DLA standalone loadable: Disabled\n",
      "[01/14/2026-07:46:57] [I] Allow GPU fallback for DLA: Disabled\n",
      "[01/14/2026-07:46:57] [I] DirectIO mode: Disabled\n",
      "[01/14/2026-07:46:57] [I] Restricted mode: Disabled\n",
      "[01/14/2026-07:46:57] [I] Skip inference: Disabled\n",
      "[01/14/2026-07:46:57] [I] Save engine: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/hs/fp16.engine\n",
      "[01/14/2026-07:46:57] [I] Load engine: \n",
      "[01/14/2026-07:46:57] [I] Profiling verbosity: 0\n",
      "[01/14/2026-07:46:57] [I] Tactic sources: Using default tactic sources\n",
      "[01/14/2026-07:46:57] [I] timingCacheMode: local\n",
      "[01/14/2026-07:46:57] [I] timingCacheFile: \n",
      "[01/14/2026-07:46:57] [I] Enable Compilation Cache: Enabled\n",
      "[01/14/2026-07:46:57] [I] Enable Monitor Memory: Disabled\n",
      "[01/14/2026-07:46:57] [I] errorOnTimingCacheMiss: Disabled\n",
      "[01/14/2026-07:46:57] [I] Preview Features: Use default preview flags.\n",
      "[01/14/2026-07:46:57] [I] MaxAuxStreams: -1\n",
      "[01/14/2026-07:46:57] [I] BuilderOptimizationLevel: -1\n",
      "[01/14/2026-07:46:57] [I] MaxTactics: -1\n",
      "[01/14/2026-07:46:57] [I] Calibration Profile Index: 0\n",
      "[01/14/2026-07:46:57] [I] Weight Streaming: Disabled\n",
      "[01/14/2026-07:46:57] [I] Runtime Platform: Same As Build\n",
      "[01/14/2026-07:46:57] [I] Debug Tensors: \n",
      "[01/14/2026-07:46:57] [I] Distributive Independence: Disabled\n",
      "[01/14/2026-07:46:57] [I] Mark Unfused Tensors As Debug Tensors: Disabled\n",
      "[01/14/2026-07:46:57] [I] Input(s)s format: fp32:CHW\n",
      "[01/14/2026-07:46:57] [I] Output(s)s format: fp32:CHW\n",
      "[01/14/2026-07:46:57] [I] Input build shapes: model\n",
      "[01/14/2026-07:46:57] [I] Input calibration shapes: model\n",
      "[01/14/2026-07:46:57] [I] === System Options ===\n",
      "[01/14/2026-07:46:57] [I] Device: 0\n",
      "[01/14/2026-07:46:57] [I] DLACore: \n",
      "[01/14/2026-07:46:57] [I] Plugins:\n",
      "[01/14/2026-07:46:57] [I] setPluginsToSerialize:\n",
      "[01/14/2026-07:46:57] [I] dynamicPlugins:\n",
      "[01/14/2026-07:46:57] [I] ignoreParsedPluginLibs: 0\n",
      "[01/14/2026-07:46:57] [I] \n",
      "[01/14/2026-07:46:57] [I] === Inference Options ===\n",
      "[01/14/2026-07:46:57] [I] Batch: Explicit\n",
      "[01/14/2026-07:46:57] [I] Input inference shapes: model\n",
      "[01/14/2026-07:46:57] [I] Iterations: 10\n",
      "[01/14/2026-07:46:57] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/14/2026-07:46:57] [I] Sleep time: 0ms\n",
      "[01/14/2026-07:46:57] [I] Idle time: 0ms\n",
      "[01/14/2026-07:46:57] [I] Inference Streams: 1\n",
      "[01/14/2026-07:46:57] [I] ExposeDMA: Disabled\n",
      "[01/14/2026-07:46:57] [I] Data transfers: Enabled\n",
      "[01/14/2026-07:46:57] [I] Spin-wait: Disabled\n",
      "[01/14/2026-07:46:57] [I] Multithreading: Disabled\n",
      "[01/14/2026-07:46:57] [I] CUDA Graph: Disabled\n",
      "[01/14/2026-07:46:57] [I] Separate profiling: Disabled\n",
      "[01/14/2026-07:46:57] [I] Time Deserialize: Disabled\n",
      "[01/14/2026-07:46:57] [I] Time Refit: Disabled\n",
      "[01/14/2026-07:46:57] [I] NVTX verbosity: 0\n",
      "[01/14/2026-07:46:57] [I] Persistent Cache Ratio: 0\n",
      "[01/14/2026-07:46:57] [I] Optimization Profile Index: 0\n",
      "[01/14/2026-07:46:57] [I] Weight Streaming Budget: 100.000000%\n",
      "[01/14/2026-07:46:57] [I] Inputs:\n",
      "[01/14/2026-07:46:57] [I] Debug Tensor Save Destinations:\n",
      "[01/14/2026-07:46:57] [I] Dump All Debug Tensor in Formats: \n",
      "[01/14/2026-07:46:57] [I] === Reporting Options ===\n",
      "[01/14/2026-07:46:57] [I] Verbose: Disabled\n",
      "[01/14/2026-07:46:57] [I] Averages: 10 inferences\n",
      "[01/14/2026-07:46:57] [I] Percentiles: 90,95,99\n",
      "[01/14/2026-07:46:57] [I] Dump refittable layers:Disabled\n",
      "[01/14/2026-07:46:57] [I] Dump output: Disabled\n",
      "[01/14/2026-07:46:57] [I] Profile: Disabled\n",
      "[01/14/2026-07:46:57] [I] Export timing to JSON file: \n",
      "[01/14/2026-07:46:57] [I] Export output to JSON file: \n",
      "[01/14/2026-07:46:57] [I] Export profile to JSON file: \n",
      "[01/14/2026-07:46:57] [I] \n",
      "[01/14/2026-07:46:57] [I] === Device Information ===\n",
      "[01/14/2026-07:46:57] [I] Available Devices: \n",
      "[01/14/2026-07:46:57] [I]   Device 0: \"NVIDIA H100 PCIe\" UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:46:57] [I]   Device 1: \"NVIDIA H100 PCIe\" UUID: GPU-ad162803-098e-b980-5e1b-5623d5adc58b\n",
      "[01/14/2026-07:46:57] [I] Selected Device: NVIDIA H100 PCIe\n",
      "[01/14/2026-07:46:57] [I] Selected Device ID: 0\n",
      "[01/14/2026-07:46:57] [I] Selected Device UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:46:57] [I] Compute Capability: 9.0\n",
      "[01/14/2026-07:46:57] [I] SMs: 114\n",
      "[01/14/2026-07:46:57] [I] Device Global Memory: 81079 MiB\n",
      "[01/14/2026-07:46:57] [I] Shared Memory per SM: 228 KiB\n",
      "[01/14/2026-07:46:57] [I] Memory Bus Width: 5120 bits (ECC enabled)\n",
      "[01/14/2026-07:46:57] [I] Application Compute Clock Rate: 1.755 GHz\n",
      "[01/14/2026-07:46:57] [I] Application Memory Clock Rate: 1.593 GHz\n",
      "[01/14/2026-07:46:57] [I] \n",
      "[01/14/2026-07:46:57] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
      "[01/14/2026-07:46:57] [I] \n",
      "[01/14/2026-07:46:57] [I] TensorRT version: 10.12.0\n",
      "[01/14/2026-07:46:57] [I] Loading standard plugins\n",
      "[01/14/2026-07:46:57] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 44, GPU 6989 (MiB)\n",
      "[01/14/2026-07:47:00] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1927, GPU +8, now: CPU 2173, GPU 6999 (MiB)\n",
      "[01/14/2026-07:47:00] [I] Start parsing network model.\n",
      "[01/14/2026-07:47:00] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:47:00] [I] [TRT] Input filename:   /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/hs_fp16.onnx\n",
      "[01/14/2026-07:47:00] [I] [TRT] ONNX IR version:  0.0.8\n",
      "[01/14/2026-07:47:00] [I] [TRT] Opset version:    17\n",
      "[01/14/2026-07:47:00] [I] [TRT] Producer name:    onnx.utils.extract_model\n",
      "[01/14/2026-07:47:00] [I] [TRT] Producer version: \n",
      "[01/14/2026-07:47:00] [I] [TRT] Domain:           \n",
      "[01/14/2026-07:47:00] [I] [TRT] Model version:    0\n",
      "[01/14/2026-07:47:00] [I] [TRT] Doc string:       \n",
      "[01/14/2026-07:47:00] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:47:00] [I] Finished parsing network model. Parse time: 0.00797158\n",
      "[01/14/2026-07:47:00] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/14/2026-07:47:24] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[01/14/2026-07:47:25] [I] [TRT] Total Host Persistent Memory: 17120 bytes\n",
      "[01/14/2026-07:47:25] [I] [TRT] Total Device Persistent Memory: 2048 bytes\n",
      "[01/14/2026-07:47:25] [I] [TRT] Max Scratch Memory: 512 bytes\n",
      "[01/14/2026-07:47:25] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 7 steps to complete.\n",
      "[01/14/2026-07:47:25] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.022896ms to assign 3 blocks to 7 nodes requiring 44040704 bytes.\n",
      "[01/14/2026-07:47:25] [I] [TRT] Total Activation Memory: 44040704 bytes\n",
      "[01/14/2026-07:47:25] [I] [TRT] Total Weights Memory: 5990912 bytes\n",
      "[01/14/2026-07:47:25] [I] [TRT] Engine generation completed in 24.9998 seconds.\n",
      "[01/14/2026-07:47:25] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 620 MiB\n",
      "[01/14/2026-07:47:25] [I] Engine built in 25.0382 sec.\n",
      "[01/14/2026-07:47:25] [I] Created engine with size: 6.19163 MiB\n",
      "[01/14/2026-07:47:25] [I] [TRT] Loaded engine size: 6 MiB\n",
      "[01/14/2026-07:47:25] [I] Engine deserialized in 0.0138079 sec.\n",
      "[01/14/2026-07:47:25] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +42, now: CPU 0, GPU 47 (MiB)\n",
      "[01/14/2026-07:47:25] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/14/2026-07:47:25] [I] Created execution context with device memory size: 42.0005 MiB\n",
      "[01/14/2026-07:47:25] [I] Using random values for input /entropy_bottleneck/Transpose_1_output_0\n",
      "[01/14/2026-07:47:25] [I] Input binding for /entropy_bottleneck/Transpose_1_output_0 with dimensions 512x128x2x2 is created.\n",
      "[01/14/2026-07:47:25] [I] Output binding for /h_s/h_s.4/Conv_output_0 with dimensions 512x384x8x8 is created.\n",
      "[01/14/2026-07:47:25] [I] Starting inference\n",
      "[01/14/2026-07:47:28] [I] Warmup completed 227 queries over 200 ms\n",
      "[01/14/2026-07:47:28] [I] Timing trace has 3409 queries over 3.00216 s\n",
      "[01/14/2026-07:47:28] [I] \n",
      "[01/14/2026-07:47:28] [I] === Trace details ===\n",
      "[01/14/2026-07:47:28] [I] Trace averages of 10 runs:\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820032 ms - Host latency: 1.3131 ms (enqueue 0.837119 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830496 ms - Host latency: 1.32656 ms (enqueue 0.847823 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824287 ms - Host latency: 1.3175 ms (enqueue 0.840137 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825865 ms - Host latency: 1.32001 ms (enqueue 0.842006 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.836757 ms - Host latency: 1.33347 ms (enqueue 0.853567 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.815672 ms - Host latency: 1.30935 ms (enqueue 0.833136 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817912 ms - Host latency: 1.3124 ms (enqueue 0.836209 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.835388 ms - Host latency: 1.33226 ms (enqueue 0.853619 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828244 ms - Host latency: 1.32485 ms (enqueue 0.845465 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822876 ms - Host latency: 1.31591 ms (enqueue 0.841238 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825381 ms - Host latency: 1.31919 ms (enqueue 0.844397 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.831174 ms - Host latency: 1.32579 ms (enqueue 0.847968 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82153 ms - Host latency: 1.31605 ms (enqueue 0.840006 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820093 ms - Host latency: 1.31227 ms (enqueue 0.837289 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82926 ms - Host latency: 1.32614 ms (enqueue 0.846124 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826294 ms - Host latency: 1.32198 ms (enqueue 0.842969 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823944 ms - Host latency: 1.31639 ms (enqueue 0.841815 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.831732 ms - Host latency: 1.32781 ms (enqueue 0.850156 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817609 ms - Host latency: 1.31365 ms (enqueue 0.834485 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832184 ms - Host latency: 1.32692 ms (enqueue 0.851419 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829266 ms - Host latency: 1.32246 ms (enqueue 0.846625 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819342 ms - Host latency: 1.313 ms (enqueue 0.837552 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.815164 ms - Host latency: 1.31161 ms (enqueue 0.831754 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825894 ms - Host latency: 1.3219 ms (enqueue 0.843732 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824579 ms - Host latency: 1.3191 ms (enqueue 0.841641 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.814087 ms - Host latency: 1.30959 ms (enqueue 0.832791 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829855 ms - Host latency: 1.32624 ms (enqueue 0.847919 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824472 ms - Host latency: 1.31747 ms (enqueue 0.842621 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824323 ms - Host latency: 1.32073 ms (enqueue 0.841083 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829282 ms - Host latency: 1.32421 ms (enqueue 0.846823 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821948 ms - Host latency: 1.31598 ms (enqueue 0.839761 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832141 ms - Host latency: 1.32778 ms (enqueue 0.849701 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821814 ms - Host latency: 1.31318 ms (enqueue 0.8379 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826605 ms - Host latency: 1.32384 ms (enqueue 0.844803 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827924 ms - Host latency: 1.32288 ms (enqueue 0.845862 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817642 ms - Host latency: 1.31016 ms (enqueue 0.835394 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824622 ms - Host latency: 1.31999 ms (enqueue 0.840503 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828674 ms - Host latency: 1.32529 ms (enqueue 0.847803 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817761 ms - Host latency: 1.30903 ms (enqueue 0.835321 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825806 ms - Host latency: 1.3217 ms (enqueue 0.842426 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824384 ms - Host latency: 1.31914 ms (enqueue 0.842163 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823132 ms - Host latency: 1.31765 ms (enqueue 0.839148 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828961 ms - Host latency: 1.32167 ms (enqueue 0.845575 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82373 ms - Host latency: 1.32089 ms (enqueue 0.840668 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832764 ms - Host latency: 1.32631 ms (enqueue 0.850726 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825043 ms - Host latency: 1.32069 ms (enqueue 0.842236 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824054 ms - Host latency: 1.31638 ms (enqueue 0.842212 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820007 ms - Host latency: 1.31808 ms (enqueue 0.839874 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.836115 ms - Host latency: 1.33255 ms (enqueue 0.851807 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823395 ms - Host latency: 1.31649 ms (enqueue 0.840796 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819238 ms - Host latency: 1.31566 ms (enqueue 0.836761 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828369 ms - Host latency: 1.32284 ms (enqueue 0.844562 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822418 ms - Host latency: 1.31875 ms (enqueue 0.840747 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.837683 ms - Host latency: 1.33282 ms (enqueue 0.856451 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830786 ms - Host latency: 1.32714 ms (enqueue 0.848267 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.833704 ms - Host latency: 1.33134 ms (enqueue 0.852356 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830841 ms - Host latency: 1.32267 ms (enqueue 0.846832 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827112 ms - Host latency: 1.32122 ms (enqueue 0.844794 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.8302 ms - Host latency: 1.32502 ms (enqueue 0.846967 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827673 ms - Host latency: 1.3218 ms (enqueue 0.842462 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821973 ms - Host latency: 1.31539 ms (enqueue 0.839978 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827093 ms - Host latency: 1.31971 ms (enqueue 0.845551 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827509 ms - Host latency: 1.32697 ms (enqueue 0.846442 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825647 ms - Host latency: 1.32005 ms (enqueue 0.843927 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826233 ms - Host latency: 1.31841 ms (enqueue 0.842926 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822766 ms - Host latency: 1.31903 ms (enqueue 0.839539 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82572 ms - Host latency: 1.32084 ms (enqueue 0.844275 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823041 ms - Host latency: 1.3162 ms (enqueue 0.841492 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830334 ms - Host latency: 1.32631 ms (enqueue 0.848724 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829352 ms - Host latency: 1.32255 ms (enqueue 0.845929 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826251 ms - Host latency: 1.32126 ms (enqueue 0.843121 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826929 ms - Host latency: 1.32106 ms (enqueue 0.844672 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823163 ms - Host latency: 1.31772 ms (enqueue 0.839368 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826257 ms - Host latency: 1.32239 ms (enqueue 0.841919 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827606 ms - Host latency: 1.32145 ms (enqueue 0.844708 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821741 ms - Host latency: 1.31515 ms (enqueue 0.838574 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829968 ms - Host latency: 1.32505 ms (enqueue 0.84837 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.831232 ms - Host latency: 1.32471 ms (enqueue 0.848309 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823438 ms - Host latency: 1.31969 ms (enqueue 0.842023 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830414 ms - Host latency: 1.32589 ms (enqueue 0.848041 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825812 ms - Host latency: 1.3205 ms (enqueue 0.843799 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825452 ms - Host latency: 1.31944 ms (enqueue 0.842792 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82146 ms - Host latency: 1.31248 ms (enqueue 0.839508 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829791 ms - Host latency: 1.3274 ms (enqueue 0.847461 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.836645 ms - Host latency: 1.33145 ms (enqueue 0.854901 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82464 ms - Host latency: 1.31972 ms (enqueue 0.84267 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82746 ms - Host latency: 1.32191 ms (enqueue 0.845136 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822119 ms - Host latency: 1.31599 ms (enqueue 0.84007 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.831537 ms - Host latency: 1.32617 ms (enqueue 0.849023 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827905 ms - Host latency: 1.32082 ms (enqueue 0.845276 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823328 ms - Host latency: 1.31709 ms (enqueue 0.842059 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832324 ms - Host latency: 1.32924 ms (enqueue 0.849707 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828784 ms - Host latency: 1.32104 ms (enqueue 0.846063 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830359 ms - Host latency: 1.32665 ms (enqueue 0.846234 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828137 ms - Host latency: 1.32493 ms (enqueue 0.846765 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.834326 ms - Host latency: 1.32944 ms (enqueue 0.853247 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82572 ms - Host latency: 1.31873 ms (enqueue 0.843591 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.814832 ms - Host latency: 1.30884 ms (enqueue 0.833215 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827148 ms - Host latency: 1.32345 ms (enqueue 0.846252 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827197 ms - Host latency: 1.31897 ms (enqueue 0.84502 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82738 ms - Host latency: 1.31759 ms (enqueue 0.845288 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.836633 ms - Host latency: 1.33174 ms (enqueue 0.852759 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827686 ms - Host latency: 1.32054 ms (enqueue 0.845764 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824207 ms - Host latency: 1.31733 ms (enqueue 0.841663 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821118 ms - Host latency: 1.31356 ms (enqueue 0.840198 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828589 ms - Host latency: 1.32156 ms (enqueue 0.843091 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.837292 ms - Host latency: 1.33296 ms (enqueue 0.854175 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.816772 ms - Host latency: 1.30845 ms (enqueue 0.833423 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820825 ms - Host latency: 1.31593 ms (enqueue 0.840381 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830676 ms - Host latency: 1.32594 ms (enqueue 0.849744 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820837 ms - Host latency: 1.31307 ms (enqueue 0.836694 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829724 ms - Host latency: 1.32239 ms (enqueue 0.847095 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82356 ms - Host latency: 1.31847 ms (enqueue 0.840332 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82677 ms - Host latency: 1.31997 ms (enqueue 0.843201 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822021 ms - Host latency: 1.3152 ms (enqueue 0.838672 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.83042 ms - Host latency: 1.32295 ms (enqueue 0.846326 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827954 ms - Host latency: 1.32275 ms (enqueue 0.84585 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827454 ms - Host latency: 1.3217 ms (enqueue 0.84436 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82655 ms - Host latency: 1.31747 ms (enqueue 0.843384 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818127 ms - Host latency: 1.31229 ms (enqueue 0.836255 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829077 ms - Host latency: 1.32288 ms (enqueue 0.846277 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821606 ms - Host latency: 1.31342 ms (enqueue 0.840271 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822412 ms - Host latency: 1.31599 ms (enqueue 0.840479 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818542 ms - Host latency: 1.31154 ms (enqueue 0.836682 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825159 ms - Host latency: 1.31982 ms (enqueue 0.841418 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825745 ms - Host latency: 1.31945 ms (enqueue 0.842859 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828516 ms - Host latency: 1.32023 ms (enqueue 0.846826 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827319 ms - Host latency: 1.32156 ms (enqueue 0.842126 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827539 ms - Host latency: 1.32343 ms (enqueue 0.84502 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821594 ms - Host latency: 1.31212 ms (enqueue 0.840161 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821082 ms - Host latency: 1.31589 ms (enqueue 0.83822 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830981 ms - Host latency: 1.32404 ms (enqueue 0.846851 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822803 ms - Host latency: 1.31467 ms (enqueue 0.840747 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827612 ms - Host latency: 1.31992 ms (enqueue 0.844348 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819995 ms - Host latency: 1.31326 ms (enqueue 0.836548 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827368 ms - Host latency: 1.31984 ms (enqueue 0.845337 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824707 ms - Host latency: 1.31753 ms (enqueue 0.841113 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825549 ms - Host latency: 1.31825 ms (enqueue 0.84292 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823352 ms - Host latency: 1.31825 ms (enqueue 0.841821 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826135 ms - Host latency: 1.32273 ms (enqueue 0.842627 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.816699 ms - Host latency: 1.30864 ms (enqueue 0.834119 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826343 ms - Host latency: 1.32068 ms (enqueue 0.841577 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.836902 ms - Host latency: 1.33093 ms (enqueue 0.854248 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.811523 ms - Host latency: 1.30205 ms (enqueue 0.828479 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827283 ms - Host latency: 1.31953 ms (enqueue 0.844189 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827368 ms - Host latency: 1.32235 ms (enqueue 0.845508 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.83064 ms - Host latency: 1.32224 ms (enqueue 0.848071 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828296 ms - Host latency: 1.32069 ms (enqueue 0.846216 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82218 ms - Host latency: 1.31216 ms (enqueue 0.840686 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825403 ms - Host latency: 1.31888 ms (enqueue 0.843274 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823206 ms - Host latency: 1.31848 ms (enqueue 0.839709 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823975 ms - Host latency: 1.31412 ms (enqueue 0.842224 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825745 ms - Host latency: 1.32175 ms (enqueue 0.845312 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826709 ms - Host latency: 1.32207 ms (enqueue 0.846729 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.815906 ms - Host latency: 1.30775 ms (enqueue 0.834766 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824976 ms - Host latency: 1.31888 ms (enqueue 0.843726 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830566 ms - Host latency: 1.325 ms (enqueue 0.845752 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830835 ms - Host latency: 1.32426 ms (enqueue 0.848816 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829822 ms - Host latency: 1.3234 ms (enqueue 0.846741 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82854 ms - Host latency: 1.321 ms (enqueue 0.845435 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820337 ms - Host latency: 1.31621 ms (enqueue 0.837134 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827478 ms - Host latency: 1.31942 ms (enqueue 0.845386 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828711 ms - Host latency: 1.32047 ms (enqueue 0.846729 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82959 ms - Host latency: 1.3245 ms (enqueue 0.846289 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824353 ms - Host latency: 1.31708 ms (enqueue 0.841577 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818958 ms - Host latency: 1.3123 ms (enqueue 0.83584 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826196 ms - Host latency: 1.31942 ms (enqueue 0.844519 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823413 ms - Host latency: 1.31572 ms (enqueue 0.841113 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.835986 ms - Host latency: 1.32957 ms (enqueue 0.851733 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826147 ms - Host latency: 1.31748 ms (enqueue 0.843396 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827734 ms - Host latency: 1.32196 ms (enqueue 0.84375 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.836829 ms - Host latency: 1.33153 ms (enqueue 0.853516 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822815 ms - Host latency: 1.31292 ms (enqueue 0.840344 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.809485 ms - Host latency: 1.30227 ms (enqueue 0.827624 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827478 ms - Host latency: 1.32148 ms (enqueue 0.844141 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.831995 ms - Host latency: 1.32432 ms (enqueue 0.849316 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821362 ms - Host latency: 1.3144 ms (enqueue 0.839807 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829736 ms - Host latency: 1.32072 ms (enqueue 0.84707 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825403 ms - Host latency: 1.32032 ms (enqueue 0.842139 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824707 ms - Host latency: 1.31824 ms (enqueue 0.841833 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817969 ms - Host latency: 1.31005 ms (enqueue 0.834583 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820911 ms - Host latency: 1.31259 ms (enqueue 0.838074 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821838 ms - Host latency: 1.31831 ms (enqueue 0.839197 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819873 ms - Host latency: 1.31013 ms (enqueue 0.838025 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822144 ms - Host latency: 1.31316 ms (enqueue 0.83877 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832971 ms - Host latency: 1.32914 ms (enqueue 0.849585 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82356 ms - Host latency: 1.31687 ms (enqueue 0.840942 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825317 ms - Host latency: 1.31691 ms (enqueue 0.841296 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823877 ms - Host latency: 1.31829 ms (enqueue 0.841138 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821741 ms - Host latency: 1.31343 ms (enqueue 0.838318 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829517 ms - Host latency: 1.32234 ms (enqueue 0.848071 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830957 ms - Host latency: 1.32352 ms (enqueue 0.849231 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821704 ms - Host latency: 1.31497 ms (enqueue 0.841089 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821741 ms - Host latency: 1.31611 ms (enqueue 0.839758 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825842 ms - Host latency: 1.31843 ms (enqueue 0.843677 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817725 ms - Host latency: 1.30884 ms (enqueue 0.834521 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827734 ms - Host latency: 1.32278 ms (enqueue 0.845691 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819446 ms - Host latency: 1.3119 ms (enqueue 0.83761 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.831555 ms - Host latency: 1.32433 ms (enqueue 0.848315 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820227 ms - Host latency: 1.31005 ms (enqueue 0.837573 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819788 ms - Host latency: 1.31229 ms (enqueue 0.83772 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826624 ms - Host latency: 1.31851 ms (enqueue 0.842944 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822607 ms - Host latency: 1.31406 ms (enqueue 0.840833 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817444 ms - Host latency: 1.31095 ms (enqueue 0.835132 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821558 ms - Host latency: 1.31748 ms (enqueue 0.839844 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820984 ms - Host latency: 1.31193 ms (enqueue 0.839087 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822766 ms - Host latency: 1.31238 ms (enqueue 0.840234 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82135 ms - Host latency: 1.31654 ms (enqueue 0.838843 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820508 ms - Host latency: 1.31565 ms (enqueue 0.8375 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830542 ms - Host latency: 1.32336 ms (enqueue 0.846582 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.81709 ms - Host latency: 1.31067 ms (enqueue 0.834619 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817969 ms - Host latency: 1.30999 ms (enqueue 0.833936 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823535 ms - Host latency: 1.31323 ms (enqueue 0.839453 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822021 ms - Host latency: 1.31477 ms (enqueue 0.837427 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827222 ms - Host latency: 1.32043 ms (enqueue 0.843506 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823242 ms - Host latency: 1.31511 ms (enqueue 0.839917 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819067 ms - Host latency: 1.31062 ms (enqueue 0.835669 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826489 ms - Host latency: 1.31882 ms (enqueue 0.843188 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826758 ms - Host latency: 1.31987 ms (enqueue 0.84397 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825684 ms - Host latency: 1.32012 ms (enqueue 0.842554 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.814917 ms - Host latency: 1.30522 ms (enqueue 0.833374 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82063 ms - Host latency: 1.31484 ms (enqueue 0.839233 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.831079 ms - Host latency: 1.32585 ms (enqueue 0.847949 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819019 ms - Host latency: 1.30845 ms (enqueue 0.836133 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832007 ms - Host latency: 1.32466 ms (enqueue 0.850439 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824854 ms - Host latency: 1.31702 ms (enqueue 0.842432 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818481 ms - Host latency: 1.30972 ms (enqueue 0.834521 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820166 ms - Host latency: 1.31272 ms (enqueue 0.83728 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822534 ms - Host latency: 1.31533 ms (enqueue 0.840723 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822314 ms - Host latency: 1.31455 ms (enqueue 0.83938 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826074 ms - Host latency: 1.31907 ms (enqueue 0.842725 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820557 ms - Host latency: 1.31208 ms (enqueue 0.838525 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826636 ms - Host latency: 1.31711 ms (enqueue 0.841406 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.8323 ms - Host latency: 1.32578 ms (enqueue 0.848804 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823535 ms - Host latency: 1.31372 ms (enqueue 0.840747 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820728 ms - Host latency: 1.31304 ms (enqueue 0.83728 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832373 ms - Host latency: 1.32502 ms (enqueue 0.84834 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824805 ms - Host latency: 1.31643 ms (enqueue 0.840503 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.830859 ms - Host latency: 1.32397 ms (enqueue 0.847803 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822876 ms - Host latency: 1.31772 ms (enqueue 0.840186 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820312 ms - Host latency: 1.31218 ms (enqueue 0.837939 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822437 ms - Host latency: 1.31443 ms (enqueue 0.839526 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829175 ms - Host latency: 1.32112 ms (enqueue 0.847217 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828809 ms - Host latency: 1.32158 ms (enqueue 0.845093 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828711 ms - Host latency: 1.32288 ms (enqueue 0.84624 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827393 ms - Host latency: 1.31726 ms (enqueue 0.843774 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826709 ms - Host latency: 1.31855 ms (enqueue 0.842041 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818726 ms - Host latency: 1.31321 ms (enqueue 0.835889 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.815967 ms - Host latency: 1.30632 ms (enqueue 0.832324 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828809 ms - Host latency: 1.31956 ms (enqueue 0.844922 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.832812 ms - Host latency: 1.32629 ms (enqueue 0.849194 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827417 ms - Host latency: 1.31931 ms (enqueue 0.843921 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826392 ms - Host latency: 1.3176 ms (enqueue 0.843066 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826294 ms - Host latency: 1.31846 ms (enqueue 0.845752 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821484 ms - Host latency: 1.3158 ms (enqueue 0.839844 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.814722 ms - Host latency: 1.30828 ms (enqueue 0.832788 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825171 ms - Host latency: 1.31665 ms (enqueue 0.841602 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818652 ms - Host latency: 1.31047 ms (enqueue 0.835864 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822559 ms - Host latency: 1.31545 ms (enqueue 0.84082 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.83418 ms - Host latency: 1.32571 ms (enqueue 0.849536 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823706 ms - Host latency: 1.31624 ms (enqueue 0.840503 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826123 ms - Host latency: 1.32019 ms (enqueue 0.841992 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82312 ms - Host latency: 1.31824 ms (enqueue 0.840381 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823535 ms - Host latency: 1.31436 ms (enqueue 0.840088 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821606 ms - Host latency: 1.31267 ms (enqueue 0.837476 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.8271 ms - Host latency: 1.32041 ms (enqueue 0.845215 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819165 ms - Host latency: 1.31143 ms (enqueue 0.837207 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827295 ms - Host latency: 1.32085 ms (enqueue 0.841382 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818555 ms - Host latency: 1.31047 ms (enqueue 0.835498 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825269 ms - Host latency: 1.31768 ms (enqueue 0.843799 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829712 ms - Host latency: 1.32161 ms (enqueue 0.844824 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827393 ms - Host latency: 1.31643 ms (enqueue 0.84458 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.83374 ms - Host latency: 1.32681 ms (enqueue 0.850537 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.816089 ms - Host latency: 1.30762 ms (enqueue 0.834009 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826001 ms - Host latency: 1.31516 ms (enqueue 0.844678 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828076 ms - Host latency: 1.32075 ms (enqueue 0.844629 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817236 ms - Host latency: 1.31343 ms (enqueue 0.837305 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.823633 ms - Host latency: 1.31382 ms (enqueue 0.841284 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.836157 ms - Host latency: 1.32893 ms (enqueue 0.851587 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821167 ms - Host latency: 1.3146 ms (enqueue 0.838452 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821216 ms - Host latency: 1.3145 ms (enqueue 0.837183 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824561 ms - Host latency: 1.31697 ms (enqueue 0.843262 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821265 ms - Host latency: 1.31184 ms (enqueue 0.837769 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82605 ms - Host latency: 1.31692 ms (enqueue 0.841333 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.815137 ms - Host latency: 1.30728 ms (enqueue 0.83335 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821191 ms - Host latency: 1.3134 ms (enqueue 0.838867 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826172 ms - Host latency: 1.31875 ms (enqueue 0.842676 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822852 ms - Host latency: 1.31755 ms (enqueue 0.838623 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827881 ms - Host latency: 1.3208 ms (enqueue 0.845972 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829956 ms - Host latency: 1.32305 ms (enqueue 0.84729 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820728 ms - Host latency: 1.31353 ms (enqueue 0.837354 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827295 ms - Host latency: 1.32007 ms (enqueue 0.845996 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825879 ms - Host latency: 1.31846 ms (enqueue 0.844458 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827148 ms - Host latency: 1.31853 ms (enqueue 0.844385 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.815405 ms - Host latency: 1.30769 ms (enqueue 0.831689 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.829883 ms - Host latency: 1.32085 ms (enqueue 0.84314 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825586 ms - Host latency: 1.3165 ms (enqueue 0.842456 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826978 ms - Host latency: 1.3179 ms (enqueue 0.844043 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828418 ms - Host latency: 1.3241 ms (enqueue 0.845142 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825342 ms - Host latency: 1.31545 ms (enqueue 0.84248 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827881 ms - Host latency: 1.31895 ms (enqueue 0.845117 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821655 ms - Host latency: 1.31643 ms (enqueue 0.837476 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828394 ms - Host latency: 1.31809 ms (enqueue 0.844067 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822021 ms - Host latency: 1.31189 ms (enqueue 0.836768 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822559 ms - Host latency: 1.31384 ms (enqueue 0.840527 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.818091 ms - Host latency: 1.31104 ms (enqueue 0.836597 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819409 ms - Host latency: 1.31184 ms (enqueue 0.83772 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.827441 ms - Host latency: 1.31902 ms (enqueue 0.844849 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824561 ms - Host latency: 1.31711 ms (enqueue 0.841235 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820703 ms - Host latency: 1.31296 ms (enqueue 0.836865 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819678 ms - Host latency: 1.31326 ms (enqueue 0.837817 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824634 ms - Host latency: 1.31318 ms (enqueue 0.841284 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82229 ms - Host latency: 1.3155 ms (enqueue 0.839819 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824292 ms - Host latency: 1.31816 ms (enqueue 0.840771 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.820776 ms - Host latency: 1.31133 ms (enqueue 0.837793 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819141 ms - Host latency: 1.31052 ms (enqueue 0.835693 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.819702 ms - Host latency: 1.31316 ms (enqueue 0.836157 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822949 ms - Host latency: 1.31335 ms (enqueue 0.838989 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825293 ms - Host latency: 1.3168 ms (enqueue 0.841235 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824194 ms - Host latency: 1.31416 ms (enqueue 0.840601 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825562 ms - Host latency: 1.31899 ms (enqueue 0.842896 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825122 ms - Host latency: 1.31321 ms (enqueue 0.840259 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.822827 ms - Host latency: 1.31531 ms (enqueue 0.838745 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.8271 ms - Host latency: 1.31807 ms (enqueue 0.843652 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824658 ms - Host latency: 1.31704 ms (enqueue 0.842725 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826904 ms - Host latency: 1.31833 ms (enqueue 0.844873 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.817798 ms - Host latency: 1.30713 ms (enqueue 0.83501 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.821167 ms - Host latency: 1.31428 ms (enqueue 0.837671 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826953 ms - Host latency: 1.31953 ms (enqueue 0.842749 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.824756 ms - Host latency: 1.31487 ms (enqueue 0.840845 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82251 ms - Host latency: 1.31433 ms (enqueue 0.839648 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828833 ms - Host latency: 1.32173 ms (enqueue 0.84585 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826709 ms - Host latency: 1.3167 ms (enqueue 0.842725 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825073 ms - Host latency: 1.31538 ms (enqueue 0.842896 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82002 ms - Host latency: 1.31194 ms (enqueue 0.83584 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.82439 ms - Host latency: 1.3175 ms (enqueue 0.841772 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.81665 ms - Host latency: 1.30881 ms (enqueue 0.832666 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.826343 ms - Host latency: 1.31697 ms (enqueue 0.842749 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.825854 ms - Host latency: 1.31877 ms (enqueue 0.8427 ms)\n",
      "[01/14/2026-07:47:28] [I] Average on 10 runs - GPU latency: 0.828955 ms - Host latency: 1.32283 ms (enqueue 0.846167 ms)\n",
      "[01/14/2026-07:47:28] [I] \n",
      "[01/14/2026-07:47:28] [I] === Performance summary ===\n",
      "[01/14/2026-07:47:28] [I] Throughput: 1135.51 qps\n",
      "[01/14/2026-07:47:28] [I] Latency: min = 1.26819 ms, max = 1.37207 ms, mean = 1.31823 ms, median = 1.32117 ms, percentile(90%) = 1.33765 ms, percentile(95%) = 1.34265 ms, percentile(99%) = 1.35229 ms\n",
      "[01/14/2026-07:47:28] [I] Enqueue Time: min = 0.796631 ms, max = 0.894775 ms, mean = 0.842274 ms, median = 0.847778 ms, percentile(90%) = 0.858917 ms, percentile(95%) = 0.862061 ms, percentile(99%) = 0.872681 ms\n",
      "[01/14/2026-07:47:28] [I] H2D Latency: min = 0.0153198 ms, max = 0.0285645 ms, mean = 0.0166274 ms, median = 0.0164185 ms, percentile(90%) = 0.017334 ms, percentile(95%) = 0.0178223 ms, percentile(99%) = 0.0205078 ms\n",
      "[01/14/2026-07:47:28] [I] GPU Compute Time: min = 0.778564 ms, max = 0.87561 ms, mean = 0.825036 ms, median = 0.829712 ms, percentile(90%) = 0.842773 ms, percentile(95%) = 0.845947 ms, percentile(99%) = 0.855835 ms\n",
      "[01/14/2026-07:47:28] [I] D2H Latency: min = 0.463989 ms, max = 0.504028 ms, mean = 0.476568 ms, median = 0.475586 ms, percentile(90%) = 0.482697 ms, percentile(95%) = 0.487793 ms, percentile(99%) = 0.494507 ms\n",
      "[01/14/2026-07:47:28] [I] Total Host Walltime: 3.00216 s\n",
      "[01/14/2026-07:47:28] [I] Total GPU Compute Time: 2.81255 s\n",
      "[01/14/2026-07:47:28] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[01/14/2026-07:47:28] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[01/14/2026-07:47:28] [W] * GPU compute time is unstable, with coefficient of variance = 1.86104%.\n",
      "[01/14/2026-07:47:28] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
      "[01/14/2026-07:47:28] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/14/2026-07:47:28] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/hs_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/hs/fp16.engine --fp16\n",
      "[OK] FP16 Engine built: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/hs/fp16.engine\n",
      "\n",
      "[Engine] Building gs engine (fp16): /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/gs/fp16.engine\n",
      "trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/gs_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/gs/fp16.engine --fp16\n",
      "&&&& RUNNING TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/gs_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/gs/fp16.engine --fp16\n",
      "[01/14/2026-07:47:28] [I] === Model Options ===\n",
      "[01/14/2026-07:47:28] [I] Format: ONNX\n",
      "[01/14/2026-07:47:28] [I] Model: /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/gs_fp16.onnx\n",
      "[01/14/2026-07:47:28] [I] Output:\n",
      "[01/14/2026-07:47:28] [I] === Build Options ===\n",
      "[01/14/2026-07:47:28] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
      "[01/14/2026-07:47:28] [I] avgTiming: 8\n",
      "[01/14/2026-07:47:28] [I] Precision: FP32+FP16\n",
      "[01/14/2026-07:47:28] [I] LayerPrecisions: \n",
      "[01/14/2026-07:47:28] [I] Layer Device Types: \n",
      "[01/14/2026-07:47:28] [I] Calibration: \n",
      "[01/14/2026-07:47:28] [I] Refit: Disabled\n",
      "[01/14/2026-07:47:28] [I] Strip weights: Disabled\n",
      "[01/14/2026-07:47:28] [I] Version Compatible: Disabled\n",
      "[01/14/2026-07:47:28] [I] ONNX Plugin InstanceNorm: Disabled\n",
      "[01/14/2026-07:47:28] [I] ONNX kENABLE_UINT8_AND_ASYMMETRIC_QUANTIZATION_DLA flag: Disabled\n",
      "[01/14/2026-07:47:28] [I] TensorRT runtime: full\n",
      "[01/14/2026-07:47:28] [I] Lean DLL Path: \n",
      "[01/14/2026-07:47:28] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
      "[01/14/2026-07:47:28] [I] Exclude Lean Runtime: Disabled\n",
      "[01/14/2026-07:47:28] [I] Sparsity: Disabled\n",
      "[01/14/2026-07:47:28] [I] Safe mode: Disabled\n",
      "[01/14/2026-07:47:28] [I] Build DLA standalone loadable: Disabled\n",
      "[01/14/2026-07:47:28] [I] Allow GPU fallback for DLA: Disabled\n",
      "[01/14/2026-07:47:28] [I] DirectIO mode: Disabled\n",
      "[01/14/2026-07:47:28] [I] Restricted mode: Disabled\n",
      "[01/14/2026-07:47:28] [I] Skip inference: Disabled\n",
      "[01/14/2026-07:47:28] [I] Save engine: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/gs/fp16.engine\n",
      "[01/14/2026-07:47:28] [I] Load engine: \n",
      "[01/14/2026-07:47:28] [I] Profiling verbosity: 0\n",
      "[01/14/2026-07:47:28] [I] Tactic sources: Using default tactic sources\n",
      "[01/14/2026-07:47:28] [I] timingCacheMode: local\n",
      "[01/14/2026-07:47:28] [I] timingCacheFile: \n",
      "[01/14/2026-07:47:28] [I] Enable Compilation Cache: Enabled\n",
      "[01/14/2026-07:47:28] [I] Enable Monitor Memory: Disabled\n",
      "[01/14/2026-07:47:28] [I] errorOnTimingCacheMiss: Disabled\n",
      "[01/14/2026-07:47:28] [I] Preview Features: Use default preview flags.\n",
      "[01/14/2026-07:47:28] [I] MaxAuxStreams: -1\n",
      "[01/14/2026-07:47:28] [I] BuilderOptimizationLevel: -1\n",
      "[01/14/2026-07:47:28] [I] MaxTactics: -1\n",
      "[01/14/2026-07:47:28] [I] Calibration Profile Index: 0\n",
      "[01/14/2026-07:47:28] [I] Weight Streaming: Disabled\n",
      "[01/14/2026-07:47:28] [I] Runtime Platform: Same As Build\n",
      "[01/14/2026-07:47:28] [I] Debug Tensors: \n",
      "[01/14/2026-07:47:28] [I] Distributive Independence: Disabled\n",
      "[01/14/2026-07:47:28] [I] Mark Unfused Tensors As Debug Tensors: Disabled\n",
      "[01/14/2026-07:47:28] [I] Input(s)s format: fp32:CHW\n",
      "[01/14/2026-07:47:28] [I] Output(s)s format: fp32:CHW\n",
      "[01/14/2026-07:47:28] [I] Input build shapes: model\n",
      "[01/14/2026-07:47:28] [I] Input calibration shapes: model\n",
      "[01/14/2026-07:47:28] [I] === System Options ===\n",
      "[01/14/2026-07:47:28] [I] Device: 0\n",
      "[01/14/2026-07:47:28] [I] DLACore: \n",
      "[01/14/2026-07:47:28] [I] Plugins:\n",
      "[01/14/2026-07:47:28] [I] setPluginsToSerialize:\n",
      "[01/14/2026-07:47:28] [I] dynamicPlugins:\n",
      "[01/14/2026-07:47:28] [I] ignoreParsedPluginLibs: 0\n",
      "[01/14/2026-07:47:28] [I] \n",
      "[01/14/2026-07:47:28] [I] === Inference Options ===\n",
      "[01/14/2026-07:47:28] [I] Batch: Explicit\n",
      "[01/14/2026-07:47:28] [I] Input inference shapes: model\n",
      "[01/14/2026-07:47:28] [I] Iterations: 10\n",
      "[01/14/2026-07:47:28] [I] Duration: 3s (+ 200ms warm up)\n",
      "[01/14/2026-07:47:28] [I] Sleep time: 0ms\n",
      "[01/14/2026-07:47:28] [I] Idle time: 0ms\n",
      "[01/14/2026-07:47:28] [I] Inference Streams: 1\n",
      "[01/14/2026-07:47:28] [I] ExposeDMA: Disabled\n",
      "[01/14/2026-07:47:28] [I] Data transfers: Enabled\n",
      "[01/14/2026-07:47:28] [I] Spin-wait: Disabled\n",
      "[01/14/2026-07:47:28] [I] Multithreading: Disabled\n",
      "[01/14/2026-07:47:28] [I] CUDA Graph: Disabled\n",
      "[01/14/2026-07:47:28] [I] Separate profiling: Disabled\n",
      "[01/14/2026-07:47:28] [I] Time Deserialize: Disabled\n",
      "[01/14/2026-07:47:28] [I] Time Refit: Disabled\n",
      "[01/14/2026-07:47:28] [I] NVTX verbosity: 0\n",
      "[01/14/2026-07:47:28] [I] Persistent Cache Ratio: 0\n",
      "[01/14/2026-07:47:28] [I] Optimization Profile Index: 0\n",
      "[01/14/2026-07:47:28] [I] Weight Streaming Budget: 100.000000%\n",
      "[01/14/2026-07:47:28] [I] Inputs:\n",
      "[01/14/2026-07:47:28] [I] Debug Tensor Save Destinations:\n",
      "[01/14/2026-07:47:28] [I] Dump All Debug Tensor in Formats: \n",
      "[01/14/2026-07:47:28] [I] === Reporting Options ===\n",
      "[01/14/2026-07:47:28] [I] Verbose: Disabled\n",
      "[01/14/2026-07:47:28] [I] Averages: 10 inferences\n",
      "[01/14/2026-07:47:28] [I] Percentiles: 90,95,99\n",
      "[01/14/2026-07:47:28] [I] Dump refittable layers:Disabled\n",
      "[01/14/2026-07:47:28] [I] Dump output: Disabled\n",
      "[01/14/2026-07:47:28] [I] Profile: Disabled\n",
      "[01/14/2026-07:47:28] [I] Export timing to JSON file: \n",
      "[01/14/2026-07:47:28] [I] Export output to JSON file: \n",
      "[01/14/2026-07:47:28] [I] Export profile to JSON file: \n",
      "[01/14/2026-07:47:28] [I] \n",
      "[01/14/2026-07:47:28] [I] === Device Information ===\n",
      "[01/14/2026-07:47:28] [I] Available Devices: \n",
      "[01/14/2026-07:47:28] [I]   Device 0: \"NVIDIA H100 PCIe\" UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:47:28] [I]   Device 1: \"NVIDIA H100 PCIe\" UUID: GPU-ad162803-098e-b980-5e1b-5623d5adc58b\n",
      "[01/14/2026-07:47:29] [I] Selected Device: NVIDIA H100 PCIe\n",
      "[01/14/2026-07:47:29] [I] Selected Device ID: 0\n",
      "[01/14/2026-07:47:29] [I] Selected Device UUID: GPU-3e2fdfe4-208f-4000-27c1-3ecf36260172\n",
      "[01/14/2026-07:47:29] [I] Compute Capability: 9.0\n",
      "[01/14/2026-07:47:29] [I] SMs: 114\n",
      "[01/14/2026-07:47:29] [I] Device Global Memory: 81079 MiB\n",
      "[01/14/2026-07:47:29] [I] Shared Memory per SM: 228 KiB\n",
      "[01/14/2026-07:47:29] [I] Memory Bus Width: 5120 bits (ECC enabled)\n",
      "[01/14/2026-07:47:29] [I] Application Compute Clock Rate: 1.755 GHz\n",
      "[01/14/2026-07:47:29] [I] Application Memory Clock Rate: 1.593 GHz\n",
      "[01/14/2026-07:47:29] [I] \n",
      "[01/14/2026-07:47:29] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
      "[01/14/2026-07:47:29] [I] \n",
      "[01/14/2026-07:47:29] [I] TensorRT version: 10.12.0\n",
      "[01/14/2026-07:47:29] [I] Loading standard plugins\n",
      "[01/14/2026-07:47:29] [I] [TRT] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 44, GPU 6989 (MiB)\n",
      "[01/14/2026-07:47:31] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1927, GPU +8, now: CPU 2173, GPU 6999 (MiB)\n",
      "[01/14/2026-07:47:31] [I] Start parsing network model.\n",
      "[01/14/2026-07:47:31] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:47:31] [I] [TRT] Input filename:   /hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/gs_fp16.onnx\n",
      "[01/14/2026-07:47:31] [I] [TRT] ONNX IR version:  0.0.8\n",
      "[01/14/2026-07:47:31] [I] [TRT] Opset version:    17\n",
      "[01/14/2026-07:47:31] [I] [TRT] Producer name:    onnx.utils.extract_model\n",
      "[01/14/2026-07:47:31] [I] [TRT] Producer version: \n",
      "[01/14/2026-07:47:31] [I] [TRT] Domain:           \n",
      "[01/14/2026-07:47:31] [I] [TRT] Model version:    0\n",
      "[01/14/2026-07:47:31] [I] [TRT] Doc string:       \n",
      "[01/14/2026-07:47:31] [I] [TRT] ----------------------------------------------------------------\n",
      "[01/14/2026-07:47:31] [I] Finished parsing network model. Parse time: 0.0057552\n",
      "[01/14/2026-07:47:31] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[01/14/2026-07:50:08] [I] [TRT] Compiler backend is used during engine build.\n",
      "[01/14/2026-07:50:24] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[01/14/2026-07:50:25] [I] [TRT] Total Host Persistent Memory: 47168 bytes\n",
      "[01/14/2026-07:50:25] [I] [TRT] Total Device Persistent Memory: 91648 bytes\n",
      "[01/14/2026-07:50:25] [I] [TRT] Max Scratch Memory: 33280 bytes\n",
      "[01/14/2026-07:50:25] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 53 steps to complete.\n",
      "[01/14/2026-07:50:25] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 2.29793ms to assign 21 blocks to 53 nodes requiring 1610751488 bytes.\n",
      "[01/14/2026-07:50:25] [I] [TRT] Total Activation Memory: 1610748416 bytes\n",
      "[01/14/2026-07:50:25] [I] [TRT] Total Weights Memory: 3022368 bytes\n",
      "[01/14/2026-07:50:25] [I] [TRT] Compiler backend is used during engine execution.\n",
      "[01/14/2026-07:50:25] [I] [TRT] Engine generation completed in 173.896 seconds.\n",
      "[01/14/2026-07:50:25] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 13832 MiB\n",
      "[01/14/2026-07:50:25] [I] Engine built in 173.947 sec.\n",
      "[01/14/2026-07:50:25] [I] Created engine with size: 3.56273 MiB\n",
      "[01/14/2026-07:50:25] [I] [TRT] Loaded engine size: 3 MiB\n",
      "[01/14/2026-07:50:25] [I] Engine deserialized in 0.0139609 sec.\n",
      "[01/14/2026-07:50:25] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1537, now: CPU 0, GPU 1539 (MiB)\n",
      "[01/14/2026-07:50:25] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[01/14/2026-07:50:25] [I] Created execution context with device memory size: 1536.13 MiB\n",
      "[01/14/2026-07:50:25] [I] Using random values for input /gaussian_conditional/Add_output_0\n",
      "[01/14/2026-07:50:25] [I] Input binding for /gaussian_conditional/Add_output_0 with dimensions 512x192x8x8 is created.\n",
      "[01/14/2026-07:50:25] [I] Output binding for x_hat with dimensions 512x3x128x128 is created.\n",
      "[01/14/2026-07:50:25] [I] Starting inference\n",
      "[01/14/2026-07:50:29] [I] Warmup completed 22 queries over 200 ms\n",
      "[01/14/2026-07:50:29] [I] Timing trace has 311 queries over 3.01647 s\n",
      "[01/14/2026-07:50:29] [I] \n",
      "[01/14/2026-07:50:29] [I] === Trace details ===\n",
      "[01/14/2026-07:50:29] [I] Trace averages of 10 runs:\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.10571 ms - Host latency: 10.3279 ms (enqueue 9.35014 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.19689 ms - Host latency: 10.4254 ms (enqueue 9.44283 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.10156 ms - Host latency: 10.3283 ms (enqueue 9.34694 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.14756 ms - Host latency: 10.3781 ms (enqueue 9.39342 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.12707 ms - Host latency: 10.3529 ms (enqueue 9.37228 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.14429 ms - Host latency: 10.3776 ms (enqueue 9.39089 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.61727 ms - Host latency: 10.8443 ms (enqueue 9.86328 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.82585 ms - Host latency: 11.0561 ms (enqueue 10.0713 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.75054 ms - Host latency: 10.9755 ms (enqueue 9.99568 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.72018 ms - Host latency: 10.9487 ms (enqueue 9.96538 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.55797 ms - Host latency: 10.7834 ms (enqueue 9.80258 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.36655 ms - Host latency: 10.5974 ms (enqueue 9.61107 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.227 ms - Host latency: 10.4565 ms (enqueue 9.47458 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.21303 ms - Host latency: 10.4448 ms (enqueue 9.45981 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.13553 ms - Host latency: 10.3641 ms (enqueue 9.38052 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.26821 ms - Host latency: 10.4984 ms (enqueue 9.5129 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.43334 ms - Host latency: 10.6656 ms (enqueue 9.67933 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.5412 ms - Host latency: 10.7706 ms (enqueue 9.78781 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.74625 ms - Host latency: 10.9755 ms (enqueue 9.99226 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.70413 ms - Host latency: 10.9365 ms (enqueue 9.95063 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.5176 ms - Host latency: 10.7498 ms (enqueue 9.76438 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.47593 ms - Host latency: 10.7078 ms (enqueue 9.72249 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.32666 ms - Host latency: 10.5606 ms (enqueue 9.57405 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.21609 ms - Host latency: 10.4464 ms (enqueue 9.46094 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.19705 ms - Host latency: 10.4243 ms (enqueue 9.44312 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.23188 ms - Host latency: 10.4611 ms (enqueue 9.47634 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.47798 ms - Host latency: 10.7119 ms (enqueue 9.72703 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.63196 ms - Host latency: 10.8641 ms (enqueue 9.87915 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.54209 ms - Host latency: 10.7712 ms (enqueue 9.78752 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.55918 ms - Host latency: 10.7882 ms (enqueue 9.80439 ms)\n",
      "[01/14/2026-07:50:29] [I] Average on 10 runs - GPU latency: 9.59087 ms - Host latency: 10.8247 ms (enqueue 9.84011 ms)\n",
      "[01/14/2026-07:50:29] [I] \n",
      "[01/14/2026-07:50:29] [I] === Performance summary ===\n",
      "[01/14/2026-07:50:29] [I] Throughput: 103.101 qps\n",
      "[01/14/2026-07:50:29] [I] Latency: min = 10.3035 ms, max = 11.0695 ms, mean = 10.6395 ms, median = 10.6292 ms, percentile(90%) = 10.9673 ms, percentile(95%) = 11.0364 ms, percentile(99%) = 11.0632 ms\n",
      "[01/14/2026-07:50:29] [I] Enqueue Time: min = 9.32648 ms, max = 10.0912 ms, mean = 9.65593 ms, median = 9.64514 ms, percentile(90%) = 9.98431 ms, percentile(95%) = 10.057 ms, percentile(99%) = 10.0731 ms\n",
      "[01/14/2026-07:50:29] [I] H2D Latency: min = 0.243317 ms, max = 0.262695 ms, mean = 0.246154 ms, median = 0.245605 ms, percentile(90%) = 0.25 ms, percentile(95%) = 0.251221 ms, percentile(99%) = 0.261719 ms\n",
      "[01/14/2026-07:50:29] [I] GPU Compute Time: min = 9.08356 ms, max = 9.84967 ms, mean = 9.40993 ms, median = 9.39917 ms, percentile(90%) = 9.73999 ms, percentile(95%) = 9.81262 ms, percentile(99%) = 9.82599 ms\n",
      "[01/14/2026-07:50:29] [I] D2H Latency: min = 0.953125 ms, max = 1.00513 ms, mean = 0.983428 ms, median = 0.982422 ms, percentile(90%) = 0.994751 ms, percentile(95%) = 0.997803 ms, percentile(99%) = 1.00342 ms\n",
      "[01/14/2026-07:50:29] [I] Total Host Walltime: 3.01647 s\n",
      "[01/14/2026-07:50:29] [I] Total GPU Compute Time: 2.92649 s\n",
      "[01/14/2026-07:50:29] [W] * Throughput may be bound by Enqueue Time rather than GPU Compute and the GPU may be under-utilized.\n",
      "[01/14/2026-07:50:29] [W]   If not already in use, --useCudaGraph (utilize CUDA graphs where possible) may increase the throughput.\n",
      "[01/14/2026-07:50:29] [W] * GPU compute time is unstable, with coefficient of variance = 2.49814%.\n",
      "[01/14/2026-07:50:29] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
      "[01/14/2026-07:50:29] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[01/14/2026-07:50:29] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v101200] [b36] # trtexec --onnx=/hwj/project/CompressAI-Science/examples/out_engines/subonnx/mbt2018-mean-q1/gs_fp16.onnx --saveEngine=/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/gs/fp16.engine --fp16\n",
      "[OK] FP16 Engine built: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/gs/fp16.engine\n",
      "\n",
      "Done. Engines saved under: /hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1\n"
     ]
    }
   ],
   "source": [
    "!python ./utils/build_engines.py \\\n",
    "--onnx_fp32 /hwj/data/model/onnx/mbt2018-mean-1-f32.onnx \\\n",
    "--onnx_fp16 /hwj/data/model/onnx/mbt2018-mean-1-f16.onnx \\\n",
    "--input_shape 512,3,128,128 \\\n",
    "--config ga-fp16,gs-fp16,ha-fp16,hs-fp16 \\\n",
    "--boundaries /hwj/project/CompressAI-Science/examples/config-mbt2018-mean-q1.json \\\n",
    "--calib_npy /hwj/project/aiz-accelerate/data/nyx-dark_matter_density.npy \\\n",
    "--out_dir /hwj/project/CompressAI-Science/examples/out_engines \\\n",
    "--model_tag mbt2018-mean-q1 \\\n",
    "--max_calib_samples 512 \\\n",
    "--prefer_cuda_ort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117b9cc",
   "metadata": {},
   "source": [
    "# Step 1 — Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43895536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/14/2026-13:55:23] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[01/14/2026-13:55:23] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[01/14/2026-13:55:23] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[01/14/2026-13:55:23] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "strings_bytes_list: [378056.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_bytes': 100663296.0,\n",
       " 'enc_ms': 13.131430435180665,\n",
       " 'dec_ms': 15.05866231918335,\n",
       " 'enc_GBps': 7.1393593000220745,\n",
       " 'dec_GBps': 6.225652585394064,\n",
       " 'strings_bytes': 378056.0,\n",
       " 'state_bytes': 104.0,\n",
       " 'total_bytes': 378160.0,\n",
       " 'bpp_strings': 0.36054229736328125,\n",
       " 'bpp_total': 0.3606414794921875,\n",
       " 'cr_strings': 266.26556912203483,\n",
       " 'cr_total': 266.19234186587687,\n",
       " 'rmse': 0.09700117260217667,\n",
       " 'nrmse': 0.09738306701183319,\n",
       " 'maxe': 0.8133085370063782,\n",
       " 'psnr': 20.230331420898438}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from compressai.zoo import bmshj2018_factorized, bmshj2018_hyperprior, mbt2018_mean\n",
    "from compressai.runtime import build_runtime\n",
    "from compressai.runtime.config import RuntimeConfig\n",
    "from compressai.runtime.codecs import GpuPackedEntropyCodec\n",
    "from compressai.runtime.utils.benchmark import run_e2e\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# 1) load net\n",
    "net = mbt2018_mean(quality=1, pretrained=False).to(device).eval()\n",
    "state = torch.load(\"/hwj/data/model/mbt2018-mean-1.pth\", map_location=device)\n",
    "net.load_state_dict(state)\n",
    "\n",
    "# 2) codec (in runtime)\n",
    "codec = GpuPackedEntropyCodec(\n",
    "    net.entropy_bottleneck,\n",
    "    gaussian_conditional=net.gaussian_conditional,\n",
    "    P=12\n",
    ")\n",
    "\n",
    "# 3) runtime (TRT, dtype auto-infer)\n",
    "cfg = RuntimeConfig(\n",
    "    model_name=\"mbt2018_mean\",\n",
    "    ga_input_dtype=torch.float16,\n",
    "    gs_input_dtype=torch.float16,\n",
    "    ha_input_dtype=torch.float16,\n",
    "    hs_input_dtype=torch.float16,\n",
    "    codec_input_dtype=torch.float32,\n",
    "    trt_engines={\n",
    "        \"ga\": \"/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ga/fp16.engine\",\n",
    "        \"gs\": \"/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/gs/fp16.engine\",\n",
    "        \"ha\": \"/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/ha/fp16.engine\",\n",
    "        \"hs\": \"/hwj/project/CompressAI-Science/examples/out_engines/engines/mbt2018-mean-q1/hs/fp16.engine\",\n",
    "    },\n",
    ")\n",
    "engine = build_runtime(net, codec, cfg)\n",
    "\n",
    "# 4) data\n",
    "arr = np.load(\"/hwj/project/aiz-accelerate/data/nyx-dark_matter_density.npy\")\n",
    "x = torch.from_numpy(arr).float().to(device)\n",
    "\n",
    "# 5) benchmark (auto stream)\n",
    "stats, x_hat, x = run_e2e(engine, codec, x, warmup=5, iters=10)\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2304e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0.0 0.9960784316062927 False False\n",
      "[01/13/2026-14:15:48] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "[01/13/2026-14:15:48] [TRT] [W] Using default stream in enqueueV3() may lead to performance issues due to additional calls to cudaStreamSynchronize() by TensorRT to ensure correct synchronization. Please use non-default stream instead.\n",
      "x_hat: -0.1768798828125 1.21875 False False\n"
     ]
    }
   ],
   "source": [
    "print(\"x:\", x.min().item(), x.max().item(), torch.isnan(x).any().item(), torch.isinf(x).any().item())\n",
    "pack = engine.compress(x)\n",
    "x_hat = engine.decompress(pack)\n",
    "print(\"x_hat:\", x_hat.min().item(), x_hat.max().item(), torch.isnan(x_hat).any().item(), torch.isinf(x_hat).any().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c95b2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_hat: -0.1768798828125 1.21875 False False\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    pack = engine.compress(x)\n",
    "    x_hat = engine.decompress(pack)\n",
    "    \n",
    "print(\"x_hat:\", x_hat.min().item(), x_hat.max().item(), torch.isnan(x_hat).any().item(), torch.isinf(x_hat).any().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece16469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compressai-s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
